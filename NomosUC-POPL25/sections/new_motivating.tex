%In this section we discuss how import is encoded into session types, how processes in NomosUC use import, motivate our adaptation of import into \emph{import session types} (IST), and the relevant type rules for making judgements on polynomial time.
IST allows processes to send import to each other algonside messages like with ITMs, but concretizes the accounting of actual computation steps through a resource called \emph{potential}~\cite{das2018work,dasnomos}.
Recall that an ITM that possesses $n'$ net import (= import received - import sent) can do at most $T(n')$ computation for some polynomial $T$.
In NomosUC, we say that a process with $n'$ import posseses at most $T(n')$ potential.
When a process takes computation steps, it is bounded by the potential it possesses, and runtime in IST is checked against a user-defined polynomial that is provided as a parameter at comple-time.

Unlike import, potential is never exchanged between processes, but is generated by ``consuming'' import.
Generating potential creates a runtime budget for the process, affects the amount of import it has remaining (to send to another process), and makes explicit how much import has been ``consumed'' by the work already done.
For example, if a process with potential $T(n')$ generates $X < T(n')$ potential, then it can send $k$ import to another process only if $X \leq T(n'-k)$.
%Generated potential creates a runtime budget for the calling process and affects the amount of import it has remaining and makes explicit how much import is ``consumed'' by the process: if a process $P$ with $n'$ tokens generates $X$ potential and performs work $X < T(n')$ it can only send $k$ import if $X \leq T(n'-k)$.
Concrete potential makes it possible to make a judgment about computation in the type system.

\paragraph{Why another resource?} 
%Why is it necessary to add another resource on top of import rather than directly account of runtime through import?
We first address the question of why another resource is needed to bound the execution of indivual processes rather than treating import as the direct accounting value.
%In general, an arbitrary mechanism for bounding runtime can be realized by a linear resource (like in Das et al.~\cite{das2018work}), but absracting runtime through a polynomial in import is critical and requires a separate resource to track work performed.
The motivation for not using import as the direct accounting resource is that it would greatly restrict for which protocols emulation is possible.
The design is suggested by Canetti~\cite{canettiUC} in the formulation of UC and the import mechanism, and we largely defer to the framework to motivate and explain it.
%In the general case of bounding runtime, a single linear resource is sufficient to control the runtime of processes (like the work by Das et al.~\cite{rast}), however, in UC we are concerned with capturing a realistic computation model and doing so leaks information that otherwise shouldn't be known. 
At a high level, using only import allows an ITM to precisely control the runtime of another that it gives import to, and the runtime that the receiving ITM needs is information that is unknown apriori. 
The environment, in this setting, gives the same import to the real and ideal worlds and forces them to take exactly the same number of steps. 
This would allow it to distinguish between the two worlds as long as they perform different amounts of work, and it would do so using information that shouldn't be known to it in any realistic setting. 
\footnote{The specific example given by Canetti~\cite{canettiUC}: ``For instance, the initial ITI $I$ can start in a rejecting state, and then pass control to another ITI $M$. If $I$ ever gets activated again, it moves to an accepting state. Whether $I$ is activated again depends on the running time of $M$. If it exceeds the computation given to it (known by $I$) then $I$ accepts depending on information that should not be ``legitimately known'' to $I$.}.
Furthermore, from a programming point of view, a programmer can't anticipate what inputs its protocol might receive and attempting to type check through trial and error setting precise import allocation is undesriable.

%The database functionality performs potentially quadratic work, in total, in the number of items stored (or, equivalently, in the number of activations): a sequence of $n$ inserts and queries results in $O(n^2)$ work iterating over $\ell$.
%In this section we introduce how processes like \Fdb receive and use import, motivate our design for adding import to NomosUC, and the relevant typing rules for making judgements on polynomial time.
%Specifically, we adapt import into session types and create \emph{import session types} (IST).
%IST allows processes to send each other import over channels and accounts for the number of computation steps a process can take through a resource called \emph{potential}~\cite{das2018work,dasnomos}.
%Recall that an ITM that possesses $n'$ net import (= import received - import sent) can do at most $T(n')$ computation for some polynomial $T$.
%In NomosUC, we say that such an ITM has at most $T(n')$ potential.
%Runtime in IST is checked against a concrete polynomial given as a parameter at compile time. 
%We account for the actual work performed by a process with \emph{potential} where every step costs 1 unit of potential.

%\paragraph{Why another resource?} 
%%Why is it necessary to add another resource on top of import rather than directly account of runtime through import?
%In general, an arbitrary mechanism for bounding runtime can be realized by a linear resource (like in Das et al.~\cite{das2018work}), but absracting runtime through a polynomial in import is critical and requires a separate resource to track work performed.
%This design is motivated by Canetti~\cite{canettiUC}.
%%In the general case of bounding runtime, a single linear resource is sufficient to control the runtime of processes (like the work by Das et al.~\cite{rast}), however, in UC we are concerned with capturing a realistic computation model and doing so leaks information that otherwise shouldn't be known. 
%At a high-level, using import as the the unit of computation allows an ITM to precisely control the runtime of an ITM it gives import to, giving it information about the other's state that, realistically, it shouldn't know.
%For example, imagine a real world and an ideal world where the environment uses import to control exactly the number of steps each world is can take.
%The differing ITMs will perform different work and terminate at different times, and \Z can use this information to artificially distinguish between them.
%\footnote{The specific example given by Canetti~\cite{canettiUC}: ``For instance, the initial ITI $I$ can start in a rejecting state, and then pass control to another ITI $M$. If $I$ ever gets activated again, it moves to an accepting state. Whether $I$ is activated again depends on the running time of $M$. If it exceeds the computation given to it (known by $I$) then $I$ accepts depending on information that should not be ``legitimately known'' to $I$.}.


\subsection{Giving Runtime To Processes}
We introduce two new type constructors to define the import sent with messages using IST: $\getpot$ and $\paypot$.
They are highlighted in red in the session types for \Fcom and \Fro in the previous section.
Canonically, the internal choice operator $\ichoice$ is paired with $\getpot$ and the external choice $\echoice$ with $\paypot$.

In the case of \Fcom, sender must always send two import when sending label $\mb{commit}$ and none when sending $\mb{open}$.
Similarly, \Fcom sends one import to the receiver when sending label $\mb{rcommit}$ and none when sending $\mb{ropen}$.
In UC, the adversary never receives any import from a functionality or protocol parties.

In the case of \Fro, over the course of its execution it must traverse a list per activation.
Over the course of $n$ activations it does $O(n^2)$ work.
Performing this necessitates that it have net positive import, therefore its session type indicates that it receives 1 import per activation and never gives any back.
\Fcom, on the other hand, is one-shot and does constant work per activation. Yet, we still give it import so that a protocols that realizes it, with the same session type, isn't also restricted to constant work and can be arbitrarily complex.

\input{figures/prot_com}

\paragraph{Exchanging Import in NomosUC}
In process code, the new type operators for import are paired with two operators in process code: \ipay and \iget.
In Figure~\ref{fig:protcom}, we see the analogous case of the sender's code at the commit stage for $\pi_\m{com}$. 
On line 8, we see the protocol explicitly specifies that it's receiving two import from \Z on \m{commit}.
Similarly on lines 11 and 15, it spends 1 import each to get the hash commitment of its bit and to send it to the receiver.
The indivual party code here does constant work: it is only activated twice and does constant work on each activation.
The random oracle does possibly polynomial work and therefore all the import that the sender receives from \Z is used to interact with \Fro.
\todo{Fro here is also the channel}

%\subsection{Giving Import to \Fdb}
%Quadratic work over $n$ insertions and accesses to \Fdb, necessitates import linear in $n$.
%Therefore, we add an import requirement to the session types between \Fdb and the protocol parties (and \A).
%
%%We introduce \emph{import session types (IST)} to express and exchange import between processes. 
%%Unlike resource-aware session types, resource sent with import session types implies computation polynomial in the amount sent rather than linear. 
%We introduce two new type constructors:  $\getpot$ and $\paypot$.
%The \Fdb session type now becomes:
%\begin{tabbing}
%    $\mi{type} \; \m{db[k][v]} = \ichoice{$\=$\textcolor{red}{\paypot{1}}$\=$ \; \mb{store}:\m{PID} \arrow \m{k} \arrow$ \\
%    \>\>$\echoice{ \mb{OK}: \m{PID} \arrow \m{db[k][v]}},$ \\
%    \>$\textcolor{red}{\paypot{1}}$\=$ \; \mb{get}: \m{PID} \arrow \m{k} \arrow$ \\
%    \>\>$\echoice{$\=$\mb{yes}: \m{v} \arrow \m{db[k][v]},$ \\

%    \>\>\>$\mb{no}: \m{db[k][v]}}}$
%\end{tabbing}
%The calling party sends import using the $\paypot$ operator and \Fdb sends import using the $\getpot$ operator.
%In this case, the type enforces that 1 import token is sent when a party takes the $\ichoice$ and calls \Fdb, and \Fdb never sends any import back.
%\footnote{Rather than explicitly place a $\textcolor{red}{\getpot{0}}$ we omit the operator altogether.}
%This session type ensures \Fdb possesses $n$ import after $n$ activations. 

%In NomosUC process code, we introduce new operations to let processes exchange the import specified by the session type and use potential to account for the work done.
%The same \Fdb process code from Section~\ref{sec:example} is augmented with the commands \inline{$\nget$} and \inline{$\npay$} for sending/receiving import. 
%Below we show the case of \inline{store} in \Fdb and the corresponding party paying the import (lines 6 and 4, in \red{red}).
%\begin{lstlisting}[basicstyle=\scriptsize\BeraMonottFamily, frame=single, mathescape, numbers=left, xleftmargin=2em, xrightmargin=2em,firstnumber=3]
%$\tg{...}$
%$\ncase$ $\$$p2f (
%  store => pid,(k',v') = $\nrecv$ $\$$p2f
%    $\tr{get {1} \$p2f}$
%    $\ngenpot$(length l + 2)
%    $\ntick$(1)
%    $\$$tb' <- pappend[(k,v)] <- $\$$tb k' v' ;
%    $\ntick$(1)
%    $\$$p2f.Ok; $\nsend$ $\$$p2f pid ;
%    $\$$c $\leftarrow$ Fdb[k][v] <- $\tg{(* args *)}$ $\$$tb'
%$\tg{...}$
%\end{lstlisting}
%$\nproc$ Fdb[k][v]: ($\$$p2f: db[k][v]), ($\$$f2p: 1), 
%  ($\$$a2f: adv[k][v]), ($\$$f2a: 1), (l: [(k,v)]) |- ($\$$c: 1) =
%{

%    retrieve => pid,k' = $\nrecv$ $\$$p2f ;
%      $\tr{get {1} \$p2f}$
%      b $\leftarrow$ exist $\leftarrow$ $\$$tb k' ;
%      $\nif$ b $\nthen$
%        v' $\leftarrow$ get $\$$tb k' ;
%        $\$$p2f.yes; $\nsend$ $\$$p2f pid; $\nsend$ $\$$p2f v';
%      $\nelse$
%        $\$$p2f.no; $\nsend$ $\$$p2f pid ;
%      $\$$c $\leftarrow$ Fdb[k][v $\leftarrow$ $\tg{(* args *)}$ 
%\begin{lstlisting}[basicstyle=\scriptsize\BeraMonottFamily, frame=single, mathescape, numbers=left, xleftmargin=2em, xrightmargin=2em,firstnumber=4]
%$\$$p2f.store ; $\tr{pay {1} \$p2f}$
%$\nsend$ $\$$p2f pid ; 
%$\nsend$ $\$$p2f someK ; $\nsend$ $\$$p2f someV ;
%$\ncase$ $\$$p2f ( Ok => 1 )
%\end{lstlisting}
%$\nproc$ somparty[k][v]: (pid: PID), ($\$$p2f: db[k][v]), 
%  ($\$$f2p: 1)  |- ($\$$c: 1) =
%{
%}

%\subsection{Potential Mechanism}
%Import in UC allows for polynomial runtime, and, in a sense, import is \emph{consumed} when a computation is performed. 
%The UC security definition only cares that there is \emph{some} polynomial to bound an ITM's runtime.
%In NomosUC, we are explicit about the polynomial used, and type-checking a collection of processes relies on a concrete polynomial that runtime is checked agains.
%In order to actually account for runtime, another concrete value is needed: \emph{potential}.
%
%The potential mechanism directly determines how much import a process has actually consumed by measuring how much comutation it does and is still able to do.
%Specifically, we want to ensure the following situation is caught by NomosUC.
%Two processes $A$ and $B$ shouldn't be able to send 1 import back and forth and \emph{both} perform polynomial from that 1 token.
%
%For example, when a process $A$ sends import to another process, the type system must ensure
%that the computation already performed by $A$ is still polynomially bounded by the import remaining after sending import.
%In other words, two processes $A$ and $B$ shouldn't be able to send 1 import back and forth and perform polynomial from that 1 token.
%$A$ performing a polynomial computation with the single import and sending it to $B$ should fail to type check. 
%Potential is related to import by the following statement: if a process
%possesses $n`$ net import then it has potential of $T(n')$, and it can not take more than $T(n')$ computational steps.
%Potential is never exchanged between processes and is checked in relation to the net import a process has. If a process performs 
%$X < T(n)$ steps and sends an import to another process such that $X > T(n-1)$, NomosUC fails to type-check the process (we leave all typing rules to the end of the section).

\paragraph{Potential}
NomosUC processes must be explicity about how much potential they use through two new keywords: \inline{$\ngenpot$} and \inline{$\ntick$}.
A UC proof on paper can theoretically reason about the execution of a ITM, but we require a concrete accounting mechanism for doing the same for NomosUC processes. 
The type system tracks, for every process, the cumulative amount of potential generated by the process, $q$, and the current remaining potential, $q'$. We elaborate on the details of the type system in a later section.
To perform $r$ work, a process must first generate $r$ potential with \inline{$\ngenpot$}(r) resulting in $q+r$ and $q'+r$ potential (line 9).
Then the process accounts for taking $x$ steps by calling \inline{$\ntick$(x)} resulting in remaining potential $q'-x$.
We exclude the calls to \igp and \itick in Figure~\ref{fig:protcom} to save space, but, in general, instead of manually inserting a \itick everywhere, NomosUC can be instrumented to insert a \itick before every operation that it performs.
The typing rules at the end of the section use $q$ and $q'$ to judge \emph{valid} NomosUC processes.
%The function call to \inline{pappend} performs \itick operations, but the calling process generates the potential.
%Therefore, conservatively, \Fdb generates enough potential to expend unit cost for accessing each item in the list (line 4).
%In this code section, we rely on \inline{pappend} to execute \inline{$\ntick$} operations of it own, and \Fdb and deducts potential before performing a message send back to the party (line 7).
%\begin{lstlisting}[basicstyle=\scriptsize\BeraMonottFamily, frame=single, mathescape, numbers=left, xleftmargin=2em, xrightmargin=2em]
%$\tg{...}$
%$\ncase$ $\$$p2f (
%  store => pid,(k',v') = $\nrecv$ $\$$p2f
%    $\tr{get {1} \$p2f}$
%    $\ngenpot$(length l)
%    $\$$tb' <- pappend[(k,v)] <- $\$$tb k' v' ;
%    $\ntick$(1)
%    $\$$p2f.Ok; $\nsend$ $\$$p2f pid ;
%    $\$$c $\leftarrow$ Fdb[k][v] <- $\tg{(* args *)}$ $\$$tb'
%$\tg{...}$
%\end{lstlisting}
%Additionaly, abstracting import into a sub-resource called potential makes the UC framework all the more expressive.
%If import was used to count and bound computation directly, rather than through a polynomial, the \Fdb example becomes untennable. 
%A party querying \Fdb has to know how long the list is so it sends enough import to iterate over it, and it doesn't know how many items other parties may have added.
%This leads to a bizarre setting where parties must attempt to learn information about the list size or keep trying higher increments of import to complete a query.
%Constraining runtime in this way makes the framework unnecessarily cumbersome.

%Imagine the database session type specified 1 import token is exchanged in both directions: 1 token from parties when querying and 1 token back from \Fdb with the result. 
%Without a concrete resource to track the actual com
%For example, without the potential mechanism the following processes set would type check but obviously violates the rules of import. 
%
%\begin{tabbing}
%   $\mi{type} \; \m{atob} = \ichoice{\textcolor{red}{\paypot{1}} \; \mb{give}: \echoice{\textcolor{red}{\getpot{1}} \; \mb{receive}: \m{atob}}}$
%\end{tabbing}
%
%\begin{lstlisting}[basicstyle=\footnotesize\BeraMonottFamily, mathescape, frame=single]
%$\nproc$ A : (bigNumr: Int), ($\$$a2b: atob) |- ($\$$ch: 1) = {
%  $\text{\color{Red}{genPot k}}$
%  let bigNum = bigNum * 2 ;
%  $\$$a2b.give; $\npay$ {1} $\$$a2b ;
%  $\ncase$ $\$$a2b ( receive => $\nget$ {1} $\$$a2v )
%  $\$$ch <- A bigNum $\$$a2b ;
%}
%
%$\nproc$ B : (bigNum: Int), ($\$$a2b: atob) |- ($\$$ch: 1) = {
%  $\ncase$ $\$$a2b (
%    give => $\nget$ {1} $\$$a2b ;
%      $\text{\color{Red}{genPot k}}$
%      $\nlet$ bigNum = bigNum * 2 ;
%      $\$$a2b.receive ; $\npay$ {1} $\$$a2b ;
%      $\$$ch <- B <- bigNum $\$$a2b ;
%  )
%}
%\end{lstlisting}
%
%Without additional rules for accounting for potential (lines 2 and 12), and \emph{consuming} import, the above system would violate the basic import mechanism as defined by UC.

%Furthermore, abstracting potential from import has the added benefit of a more expressive framework.
%Take the database ideal functionality below as an example. 
%When a party performs a read, it doesn't know the size of the list before-hand. 
%Using only import as the accounting for computation, the protocol party would always have to give a precise amount of import to ensure the whole list can be read. 
%With potential, a single unit of import is enough for the functionality to determine how much polynomial computation (in this case, linear) needs to be done.  
%
%\begin{tabbing}
%   $\mi{type} \; \m{db[k][v]} = \ichoice{$\=$\textcolor{red}{\paypot{1}}$\=$ \; \mb{store}:\m{PID} \arrow \m{k} \arrow$ \\
%   \>\>$\echoice{ \mb{OK}: \m{PID} \arrow \m{db[k][v]}},$ \\
%   \>$\textcolor{red}{\paypot{1}}$\=$ \; \mb{get}: \m{PID} \arrow \m{k} \arrow$ \\
%   \>\>$\echoice{$\=$\mb{yes}: \m{v} \arrow \m{db[k][v]},$ \\
%   \>\>\>$\mb{no}: \m{db[k][v]}}}$
%\end{tabbing}
%
%\todo{fdatabase is nontrivial, how much of it to include? maybe only where it iterates over the list and generates n potential to do it}
%\begin{bbox}[title={Functionality $\F_{\msf{db}}$}]
%
%Initialize list $l := []$
%
%\OnInput \inmsg{add}{$x$} form $P_i$:
%   \begin{ritemize}
%       \item Append $x$ to $\ell$
%       \item \Send $ok \rightarrow P_i$
%   \end{ritemize}
%
%\OnInput \inmsg{get}from $P_i$:
%   \begin{ritemize}
%       \item \Send $\ell \rightarrow P_i$
%   \end{ritemize}
%\end{bbox}

\subsection{Virtual Tokens}
Our realization of import so far adheres to the design specified by Canetti et al~\cite{canettiUC}.
We encounter a subtle problem realizing a common UC design pattern in NomosUC: ITMs sandboxing, or running internally, other ITMs.
Simulators, in particular, rely on this design pattern to emulate real-world protocols, rewind them, replay them, and override their randomness.
Allowing processes in NomosUC to do the same results in some issues with execution cost analysis.
Specifically, this issues arises in the simulator we use to for the proof of realization for \protcom.

A simulator for \protcom is straightforward but elucidates and highlights additional design challenges necessary to overcome.
We focus on the case of the corrupt sender and include the full simulator in Appendix~\ref{app:commitment}.

We define a simulator for the dummy adversary in the real world.
The dummy adversary suffices for an emulation proof, because it's the strongest possible adversary and there is a deterministic function for adapting a simulator for the dummy adversary to a simulator for any other adversary.
In the real world with a corrupt sender, \Z observes no messages received from the receiver, and tries to create a commitment and open it to the receiver.
The ideal world simulator \Sim must ensure that the ideal world opens only if the real world succesfully opens and ensures that the ideal world commits to the same bit as the real world.
As is common in many UC proofs, simulator's sandbox some or all of the real world.
For commitment, \Sim wants to internally run \Fro and use it to handle inputs from \Z, and use it to observe preimages and ensure the commitment is io
This is done by \Sim by sandboxing \Fro, reading \Z's requests to compute hashes on behalf of the corrupt sender, and peeking at the bit that was committed to.

The simulator process's type is define simply as follows where we omit the common arguments to all processes. 
\begin{lstlisting}[basicstyle=\scriptsize\BeraMonottFamily, mathescape, frame=single, numbers=left, xleftmargin=2em, xrightmargin=0em]
$\nproc$ sim_com[K][K1] : $\tg{(* standard args *)}$ 
  ($\$$z2a: Z2A[K][rop2f[commsg][roa2f]{1}), 
  ($\$$a2z: A2Z[K][ro2fp[commsg][rof2a]{0}),
  $\tg{(* other channels removed for brevity *)}$ = {
\end{lstlisting}
The simulator presents an interface to \Z that mimics the real world with \Fro, and it communicates with the corrupt sender and \Fcom through their espective types for channels \ic{a2p} and \ic{a2f}.

The simulator, running 

\paragraph*{\textbf{A Constraint Unique to NomosUC}}
Simulators in UC often run other ITMs internally in a black-box manner. 
In NomosUC, doing the same with processes comes with the added constraint of satisfying the simulated process's session type, namely its import requirement.

Suppose a simulator \Sim that sandboxes \Fro internally. 
Ideally, we want that the computation done by \Fro counts towards the total work performed by \Sim rather that requiring import of its own like its session type requires.
Unless there is a way to give \Fro some ``fake'' import, we require that simulators must effectively waste import simulating the real world rather than just the potential required to perform that same computatiuon.
The widens the gap in the simulator proofs that UC can realized by NomosUC can't.
We describe a more generic example.

Imagine a real world functionality $\F_\m{real}$ that takes one import from \A, and an ideal world functionality $\F_\m{ideal}$ that requires one import from \Sim.
\A is activaed with 2 import. One of which it uses for $\F_\m{real}$ and one it uses to perform some local polynomial amount of work.
\Sim in the ideal world must receive the same import as \A. If it must use one import to simualte $\F_\m{real}$ and one import for $\F_\m{ideal}$, it's left with no import and can only do constant work over the course of the execution.
More generally, forcing a process to give up whole import for a process it wants to simulate internally, rather than only expending the required potential, constraints what can be realized in NomosUC.

% Imagine an adversary in the real world that accepts one unit of import and uses it to query \Fro.
% The ideal world simulator is given the same single unit of import as the real world adversary, by definition, and if it must expend it to sandbox \Fro then it's left with no import to do anything else.
% This issue is further exacerbated when you consider \Sim simulating the entire real-world execution. All of its import budget is used up running the same processes as the real world rather than the sandbox counting toward its total potential budget.
% More generally, an ideal functionality in the real world, whose output depends on the amount of computation it's able to do, must perform exactly the same work when run by \Sim in order to produce the same output.
% Therefore, we formulate a mechanism to create \emph{virtual tokens} to give to sandboxed processes that satisfy its import requirements while still only counting towards the total work done by \Sim.
% Though a simple concept, realizing this in our typing rules is major contribution of this work.
% \todo{Perhaps a good way to frame it is saying that the work \Sim could otherwise do with only 1 import (sandboxing + other stuff) it now needs 2 import to do. When \Sim needs to spend import in the ideal world as well, liek interacting with the ideal functuionality it is one short and show all definitioons hafve to change to accomodate this.}

%In the ITM model, in UC, a simulator, \Sim, sandboxing \Fdb has the ITM encoded on its own tape allowing it to arbitrarily manipulate its state and execute it as necessary.
%Therefore, the computaton that \Sim and the sandboxed \Fdb perform are counted as part of \emph{the same ITM}.
%In NomosUC, there is no notion of encoding \Fdb within \Sim without rewriting its code.
%Reusing \Fdb then means treating it as \emph{a separate process}, which is undesirable.
%%In NomosUC, running \Fdb in a similar way mean reimplementing the functionality as part of the process code of \Sim. Reusing the \Fdb process means \emph{it must be treated as a separate process} 
%%%barring reimplementing the functionality as part of the code of \S, \emph{it is must be treated as a separate process} 
%%with a session type \m{db[k][v]} which requires one import sent with every message.
%In the listing below, the simulator wants to run a copy of \Fdb and communicates with it over a channel \ic{fdb} (line 5). 
%\Z gives both the dummy adversary, \DA, and \Sim a message with 1 import (line 9) intended for \Fdb in the real world, and like \DA, \Sim calls \Fdb (line 12) with 1 unit of import due to its type \m{db[k][v]} (line 13).
%%\Sim relies on the existing process to emulate the outputs \Z would see in the real world communicating with the dummy adverasry and \Fdb.
%%On line 9, \Sim gets 1 unit of import from \Z, the same the \DA gets in the real-world, and on line 13 it's forced to give it up to make the call to \Fdb and not do any polynomial work itself.
%Without giving the import, \Sim would fail to type-check, but in doing so is forced to give up its own import.
%
%More generally, a functionality in the real world, whose output depends on the amount of computation it's able to do, must do exactly the same work when run by \Sim to produce the same output.
%In the real world the dummy adversary, \DA, receiving $X$ import from \Z gives all $X$ to \F and doesn't do any other work.
%In the ideal world, \Sim runs the the real-world internally, receives the same $X$ import as \DA, and must give \F all $X$ import to ensure the same output is produced. 
%It is therefore forced to give up it's entire runtime budget, just as \DA does, and therefore can't do any additional polynomial work of its own (line 18).

%Ultimately, simply running \Fdb as a separate process constrains the kinds of simulators (and so proofs) that can be realized, and if we want our cost analysis to treat \Fdb and \Sim as one and the same, a few important questions are raised:
%does \Sim lose import and \Fdb gains import? do they both share the same import because \Fdb is sandboxed? can we tell the type system to ignore import in IST in some cases?
%
%\begin{lstlisting}[basicstyle=\scriptsize\BeraMonottFamily, frame=single, mathescape, numbers=left, xleftmargin=2em, xrightmargin=2em]
%$\nproc$ sim_db[k][v] : 
%  $\tg{(* the usual params *)}$
%  ($\$$z2a: Z2A[a2p,a2f]), ($\$$a2z: A2Z[p2a,f2a]),
%  ($\$$p2a: a2p), ($\$$f2a: f2a),
%  ($\$$fdb: db[k][v]) $\tg{(*...*)}$ |- ($\$$c: 1) =
%{
% $\nmatch$ $\$$z2a,$\$$p2a,$\$$f2a (
%    Z2A2F,*,* =>
%      $\nget$ {1} $\$$z2a
%      msg = $\nrecv$ $\$$z2a
%      $\ncase$ msg (
%        Query(k) => $\$$db.query
%          $\npay$ {1} $\$$db
%          $\nsend$ $\$$db k
%          $\ncase$ $\$$db (
%            yes => v = $\nrecv$ $\$$db 
%            _ => ()
%          x $\leftarrow$ do_poly_work ;
%  $\tg{.....}$
%\end{lstlisting}
%        Store(k,v) => $\$$db.store
%          $\npay$ {1} $\$$db
%          $\nsend$ $\$$db k ; $\nsend$ $\$$db v
%          $\ncase$ $\$$db ( Ok => 
%            x $\leftarrow$ do_poly_work ;
%            $\$$c <- sim_db[k][v] $\tg{(* args *)}$ )
%}


%% | describe the a simulated \Fdb now without virtual tokens and showcase the issue
%% | and we need to be able to reuse process definitions rather than make special virtual one
The approach we take is to allow creation of ``fake tokens'', called \emph{virtual import tokens}, and make all processes parameteric in their token typ.
We tie the amount of virtual import crated to the real import that the calling process holds.
Tokens types are represented by a token hierarchy 
\vspace{-0.5em}
\begin{mathpar}
  \mi{token types\;}\;\K_0 \to \K_1 \to ... \to \K_m
  \vspace{-0.5em}
\end{mathpar}
Where $\K_0$ are real import tokens and $\K_{i>0}$ are all virtual.
The heirarchy is a global definition used by all processes, and the number of levels $m$ in the heirarchy is statically defined, at compile-time, as the number of layers of sandbox within a sandbox.
It is statically defined to prevent infinite type creation at runtime, and we believe the loss of expressivity is insignificant.
Processd definitions all include a type parameter, \inline{K}, that they refer to as their ``real token type'' (seen in the definition of \m{protcom} above).
The main processes in the execution, the ``real processes'' such as \Z and \A, are obviously spawned with parameter $K_0$ and all sandboxes processes with $K_{i > 0}$.
Definint different token types also creates additional guard rails for sandboxxed programs: they can't communicate with process outside the sandbox, and the type system enforces it through a token type mismatch.
\plan{There used to be a code snippet here showing a process definition with the toke type paramter but it's useless we just point to the process definition of procom above}
%For example, the simulator above is now given the parameter $K_0$ (for real), and type $K_1$ as the virtual type to sandbox with:
%\begin{lstlisting}[basicstyle=\scriptsize\BeraMonottFamily, frame=single, mathescape, numbers=left, xleftmargin=2em, xrightmargin=2em]
%$\$$c $\leftarrow$ sim_db$\tr{[K0,K1]}$[k][v] $\tg{(* the usual params *)}$
%            $\tr{\^{}\^{}\^{}\^{}\^{}\^{}}$
%  ($\$$z2a: Z2A[a2p,a2f]), ($\$$a2z: A2Z[p2a,f2a]),
%  ($\$$p2a: a2p), ($\$$f2a: f2a) $\tg{...}$
%\end{lstlisting}
%The simulator, in turn, spawns an instance of \Fdb with a with  virtual token type, $K_1$ that \Fdb considers real tokens:
%\begin{lstlisting}[basicstyle=\scriptsize\BeraMonottFamily, frame=single, mathescape, numbers=left, xleftmargin=2em, xrightmargin=2em]
%$\$$fdb $\leftarrow$ Fdb$\tr{[K1]}$[k][v] $\leftarrow$ $\tg{...}$
%\end{lstlisting}

\paragraph{Creating Virtual Import}
NomosUC processes create virtual tokens by withdrawing them from their real token type. 
The operator \inline{$\nwithdraw\ $ K0 K1 n} allows a process, using its real token type $K_0$, to create $n$ new tokens of type $K_1$.
A new parameter is also added to $\npay$ and $\nget$ which specifies the token type being sent or received, so a process $P$ can spawn another process $P'$ with a virtual type $K_1$ and can pay/receive virtual tokens to/from $P'$.
A process (below) that sandboxes $\Fro$ (above) spawns it with its virtual token type (line 1), creates the virtual tokens it needs to send (line 2), and finally sends the tokens specifying the type being sent by \inline{$\npay$} (line 3).
\begin{lstlisting}[basicstyle=\scriptsize\BeraMonottFamily, frame=single, mathescape, numbers=left, xleftmargin=2em, xrightmargin=2em]
$\$$ $\leftarrow$ Fro[K+1][(Int,Bit)] <- k sid rng $\$$p2f' $\$$f2p' $\$$a2f' $\$$f2a' 
$\nwithdraw$ K0 K1 1
$\$$p2f'.query ; pay $\textcolor{red}{K1}$ {1} $\$$p2f' 
$\nsend$ $\$$p2f' x
\end{lstlisting}
In Section~\ref{sec:execuc}, we show examples of where sandboxing appears in our definition fo the UC experiment. Namely, we create an entity called the \partywrapper which internall runs protocol parties in a sandbox.
%When communicating with augmented \Fdb (above), \Sim (below) first creates the virtual tokens (line 5) and then sends them on the channel (line 6).
%Trying to give a type $K_i$ to a process whose real token type is some $K_{j \neq i}$ fails to type-check for obvious reasons.
%\begin{lstlisting}[basicstyle=\scriptsize\BeraMonottFamily, frame=single, mathescape, numbers=left, xleftmargin=2em, xrightmargin=2em]
%$\nget$ {1} $\$$z2a
%msg = $\nrecv$ $\$$z2a
%$\ncase$ msg (
%  Query(k) => 
%    $\nwithdraw$ K0 K1 1
%    $\$$db.query
%    $\npay$ $\tm{K1}$ {1} $\$$db
%    $\nsend$ $\$$db k
%    $\ncase$ $\$$db (
%      yes => v = $\nrecv$ $\$$db 
%      _ => )
%    x $\leftarrow$ do_poly_work ;
%\end{lstlisting}

\paragraph{Relating virtual tokens to real work.}
%Without relating virtual tokens to the amount of import that the sanboxing process has, we encounter an infinite runs problem where processes can continue to create virtual tokens and processes to perform super-polynomial work.
Intuitively, the number of virtual tokens created should be tied to the total runtime budget of the sandboxing process to prevent an infinite runs problem.
The number of virtual tokens created through a globally known polynomial \GlobalF defined at compile-time.
The type system requires that the virtual tokens of type $i+1$, $t_{i+1}$, created by a process $P_i$ are upper bounded by $\GlobalF(t_i, k)$ where $t_i$ is the number of tokens $P_i$ possesses of its real token type $K_i$ and $k$ is the security parameter.
%This ensures that over all virtual processes within a ``real'' process the amount of tokens is never super-polynomial in the number of real import.
The \inline{$\nwithdraw$} operator itself consume some potential, preventing a process from calling it indefinitely.
Unlike import, we don't define virtual potential, however the type system only compares the potential created/used to a polynomial \emph{in that processes's token type}.
The typing rules described next clarify on how the type system determines whether a process satisfies import-based polynomial runtime.

%Our treatment of virtual tokens bounded by a polynomial in the import a process has appears, on the surface to be identical to how we treat potential.
%A natural counter-point may be to treat potential as another virtual token in the heirarchy: make the last token in the heirarchy the potential.
%\todo{i don't know if i have a good answer for this other than it's easier. tokens don't know how deep the virtual tokens go. you can define one token type that everyone knows as potential but then there isn't really that much of a difference with that versus treating it differently. we want only one potential type to be used for compuation cost regadless of the token type of the process using it.}

%% | we need a different kind of virtual import to give to \Fb to satisfy its type and make the type system happy

%% | the keywords to create virtua tokens

%% | how do we make sure they don't exceed the polynomial constraints of the calling process?

%\subsection{Typing Rules for Import and NomosUC}
\section{Typing Rules for Import and NomosUC}
We introduce some of the base type system from Nomos augmented with import, but focus mainly on the the new additions for handling import, potential, and virtual tokens. 

% | token heirarch and token validity context 
%Session types are derived from a Curry-Howard interpretation of intuitionistic linear logic. 
A Nomos process term is assigned the following judgement: 
\[
(x_1 : A_1), (x_2 : A_2), \ldots, (x_n : A_n) \vdash P :: (z : C)
\]
which states that process $P$ \emph{provides} a service
of session type $C$ along channel $z$, \emph{using} the services of session
types $A_1, \ldots, A_n$ provided along channels $x_1, \ldots, x_n$ respectively.
For a \emph{well-formed} judgment, all channel names need to be distinct.
The linear antecedents are often abbreviated to $\D$.

The NomosUC judgment has some additional components
\[
\Sg \semi k \semi \Tokens \semi \Psi \semi \D \entailpot{q}{q'} P :: (x : A)
\]
$\Sg$ denotes the signature containing type and process definitions and $k$
denotes the security parameter.
Both of these quantities are globally known and fixed, therefore we omit them from
most typing rules for brevity.
$\Tokens$ describes the total (ever received) and current ($=$ received - sent) import tokens
of each type stored in the process.
$\Psi$ represents the functional data structures and $\D$ collects the
session-typed channels along with an optional \emph{write token} $\wt$
(to resolve non-determinism in the semantics) used by the process. \todo{Clarify what $\Psi$ actually encodes.} 
The write token globally determines which process is activated to take the next execution step.
We borrow the concept from ILC~\cite{ilc}, and, intuitively, a process sending a message must possess the write token. 
The typing rules below for $\getpot R$ nd $\getpot L$ (sending and receiving import on both endpoints of the channel) specify write token ownership, and the full typing rules for sending/receiving messages on channels (Appendix~\ref{app:basic}) details how the $\wt$ is exchanged.
Finally we denote the total potential created and the potential remaining for $P$ with $q$ and $q'$ above and below the turnstile.

The token context $\Tokens$ tracks the number of tokens of each type from the token hierarchy described in the previous section.
For each token type $\gamma_i$, $\Tokens$ stores $(t_i,t_i')$ which are the total tokens of type $i$ and the tokens of type $i$ currently owned by the process, respectively. 
We define a side condition for a process to be well-typed, and it is that its token context must always be valid \emph{w.r.t the security parameter $k$}.
To this end we define a globally known polynomial $\GlobalF : (\msf{nat}, \msf{nat}) \rightarrow \msf{nat}$ as the bound between two successive token types. UC requires this function to be \emph{super additive}, i.e. $\GlobalF(x+y,k) \geq \GlobalF(x,k) + \GlobalF(y,k)$.
The polynomial constrains the created tokens $t_{i+1} \leq \GlobalF(t_i, k)$.
We express this condition with the following inductive rules.
\begin{mathpar}
  \infer
  {\K_0 \hookrightarrow (t_0, t_0') \;\; \m{valid}(k)}
  {}
  \and
  \infer
  {\Tokens, \K_{i+1} \hookrightarrow (t_{i+1}, t_{i+1}')\;\; \m{valid}(k)}
  {\Tokens\;\; \m{valid}(k) \and
  \K_{i} \hookrightarrow (t_i, t_i') \in \Tokens \and
  t_{i+1} \leq \GlobalF(t_i',k)}
\end{mathpar}
We mandate that this condition is satisfied by all the process typing rules presented in this paper.

% | creating virtual tokens: withdraw tokens 
The first token-specific typing rule we present is creating new tokens with \inline{$\nwithdraw\ $ K0 K1 n}.
\begin{mathpar} \small
  \inferrule*[right=$\m{tok}$]
  {\textcolor{blue}{\Tokens, \K_{i+1} \hookrightarrow} (t_{\textcolor{blue}{i+1}} + n, t_{\textcolor{blue}{i+1}}' + n) \semi
  \Psi \semi\wt, \D \entailpot{\B{q}}{\B{q'}} P :: (x : A)}
  {\textcolor{blue}{\Tokens, \K_{i+1} \hookrightarrow} (t_{\textcolor{blue}{i+1}}, t_{\textcolor{blue}{i+1}}') \semi \Psi \semi \wt, \D \entailpot{\B{q}}{\B{q'}} \hspace{4em} \\
    \hspace{5em}\m{withdrawToken} \; \K_i \; n\; \K_{i+1}  \semi P :: (x : A)}
% \vspace{-0.5em}
\end{mathpar}
We highlight the importance of the constraint that only tokens of type $\gamma_i$ can create tokens of type $\gamma_{i+1}$.
Here the ``real'' token type for $P$ is $\gamma_i$ and executing \inline{$\nwithdraw$} $K_i K_{i+1} n$ increases only the virtual token counts ($t_{i+1}$ and $t_{i+1}'$) by $n$. 
The side condition of token validity ensures that $t_{i+1} + n \leq \GlobalF(t_i, k)$ where $K_i \hookrightarrow (t_i, t_i') \in \Gamma$. 

% | how does this manifest in the rules for choice: the new type constructors for sending import 
\paragraph*{\textbf{Exchanging Import Tokens}}
Here we present the full typing rule for $\getpot$ for each side of the channel.
We highlight in blue the additions when taking token types into account.
\begin{mathpar} \small
  \infer[\getpot R]
  {\textcolor{blue}{\Tokens, \K_i \hookrightarrow} (t_i, t_i') \semi \Psi \semi \D \entailpot{\B{q}}{\B{q'}} \eget{x}{r \textcolor{blue}{: \K_i}} \semi P ::
  (x : \tgetpot{A}{r \textcolor{blue}{: \K_i}})}
  {\textcolor{blue}{\Tokens, \K_i \hookrightarrow} (t_i, t_i'+r) \semi \Psi \semi \wt, \D \entailpot{\B{q}}{\B{q'}} P :: (x : A)}
  %
  \and
  %
  \inferrule*[Right=$\getpot L$]
  {\textcolor{blue}{\Tokens, \K_i \hookrightarrow} (t_i, t_i') \semi \Psi \semi \D, (x : A) \entailpot{\B{q}}{\B{q'}} P :: (z : C)}
  {\textcolor{blue}{\Tokens, \K_i \hookrightarrow} (t_i, t_i'+r) \semi \Psi \semi \wt, \D, (x : \tgetpot{A}{r \textcolor{blue}{: \K_i}}) \\\ \entailpot{\B{q}}{\B{q'}} 
  \epay{x}{r \textcolor{blue}{: \K_i}} \semi P :: (z : C)}
\end{mathpar}
In the rule $\getpot R$, process $P$ storing $(t_i, t_i')$ import tokens of type $\K_i$
receives $r$ additional $\K_i$ tokens adding it to the current token counter, thus
the continuation executes with $(t_i, t_i'+r)$ tokens of type $\K_i$.
Note that validity of token context is trivially satisfied in this case since the
process is gaining import tokens.
%
In the dual rule $\getpot L$, a process containing $(t_i, t_i'+r)$ tokens of type $\K_i$
pays $r$ units along channel $x$ leaving $(t_i, t_i')$ import tokens of type $\K_i$ with
the continuation.
In this case, the validity of the token context establishes that $t_{i+1} \leq \GlobalF(t_i',k)$,
a condition that is necessary for successful typechecking.
The typing rules for the dual constructor $\tpaypot{A}{r : \K}$
are the exact inverse and omitted for brevity.
Finally, the paying process must possess the $\wt$ and the receiver obtains it.

% | the write tokens is added: UC requires one activation at any time and so the write-token is required in the context of processes when external/internal choice are used

% | potential: genpot, tick 
\paragraph{Potential}
Potential is another key design in import session types.
The main operation to interact with the potential mechanism is processes generating  potential to be used with \igenpot and consuming it with \itick.
\begin{mathpar}
  \inferrule*[right=$\m{pot}$]
  {q+r \leq \GlobalF(t_{m}',k) \and K_{m} \hookrightarrow (t_{m}, t_{m}') \in \Tokens \\\
  k \semi \Tokens \semi \Psi \semi \wt, \D \entailpot{q+r}{q'+r} P :: (x : A)}
  {k \semi \Tokens \semi \Psi \semi \wt, \D \entailpot{q}{q'} \m{genPot} \; r \semi P :: (x : A)}
\end{mathpar}
A process initially storing $(q, q')$ potential units generates $r$ potential so that
the continuation contains $(q+r, q'+r)$ potential units.
Note, however, that the maximum potential that can be stored in a process is bounded by $\GlobalF(t_{m}',k)$
where $\GlobalF$ is the connection rate, $m$ is the simulation depth, and $k$ is the security parameter.
This restricts us from generating an unbounded amount of potential which could have violated the
polynomial execution cost bound.

Processes explicitly account for their own computation by executing \itick for every syntactic construct. NomosUC can be instrumented to automatically insert these before/after every operation.
\begin{mathpar}
  \infer[\m{tick}]
  {\Tokens \semi \Psi \semi \wt, \D \entailpot{q}{q'+r} \etick{r} \semi P :: (x : A)}
  {\Tokens \semi \Psi \semi \wt, \D \entailpot{q}{q'} P :: (x : A)}
\end{mathpar}
Note how the process starts with $q'+r$ potential units, and executing $\etick{r}$
consumes $r$ units leaving $q'$ potential for the continuation.
This is the only rule that increments the work counter of a process, and since this operation consumes $r$ units of potential, we can infer
that the total sum of potential and work of a closed set of processes will always be bounded.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\subsection{Remarks on Polynomial Time}
%\todo{ what do we want to talk about here that doesn't already exist above? }
%These are out of place remarks trying to address some comments from reviewers. There are some todo's for ankush to look over.
%
%\todo{some related work discussion from the time credits that were brought up in the latest round of reviews. like why not use those rather than import here?}
%
%\todo{should we talk about the DDH reduction here that was brought up in the first round of reviews.}
%
%We want to capture a polynomial time notion that can jugde open tersm as polynomial without factoring in what other processes they are connected to. 
%For example, we want to conclude that an adverasry is polynomial time if it performs at most polynomial work on every activation.
%Even if activated a super-polynomial number of times, the process is still considered polynomial time.
%A process providing super-polynomial activatesion of the adversary would fail to type check ensuring that this isn't a corner case which allows unbounded computation.



