% RESEARCH QUESTIONS:
%     (RQ1). Is UC suitable and practical as a development framework rather than only a theoretical framework?
%             (i). Can existing UC models/techniques be improved for an engineering purpose?
%             (ii). What are the advantages of using UC for development?
%     (RQ2). Is UC as a development framework compatible with existing informal analysis techniques?
%             (i).  Fuzz testing is widely used, is a successful analysis tool, and is itself an engineering undertaking. Can we successful apply fuzzing to UC?
%             (ii).  Does the ideal functionality model and out realization of import aid in analyzng liveness in distributed protocols?

Universal composability is the leadeding framework for defining the security of message-passing cryptographic protocols between mutually distrustful parties.
Though largely used for cryptography, it has seem a reemergence in asynchronous distributed systems literature, especially due to the rise of decentralized protocols where applications are a composition of many interacting layers of other asynchronous distributed systems with different fault models and properties.
This highly compositional nature, combined with a new setting where financial incentives make properties like fairness, output distribution, and adversarial influence more relevant, have led to increasing interest in UC for distributed protocols.
At its core the framework's appeal is that it allows protocols to be designed in isolation and rely on idealized versions of other subprotocols and assumptions that behave like trusted third parties--called \emph{ideal functionalities}. 
It security definition allows proving of protocols, also in isolation, while ensuring that the proof holds when ideal functionalities are replaced with real protocols and the protocol is composed with arbitrarhy other protocols. 
Far from only a theoretical framework, this form of design and security definition lends itself well to the this setting.
%The UC composition operator and security definition allows replacing ideal functionalities with protocols that realize them (in isolation) to realize a larger protocol. 

The ideal functionality and the real-ideal paradigm also enable a far more expressive and generalizable way to specify the properties and prove them for a protocol as a relation to an idealized version that implicitly exihibits the desired properties.
Defining and analyzing protocols this way lends itself to properties not easily expressed as a set of independent properties by existing property-based definitions.
Even for simple protocols, as we discuss later in this work, specifying these properties as independent asserts can be cumbersome and error-prone. 
We believe that these advantages and features of UC mdoelling are specifically advantageous for asynchronous distributed protocol, and, in this work, we explore whether they can be realized as a software development framework using informal analysis techniques.
The primary reason for this
The primary reason for this \emph{gap between research and software engineering} is that UC's complex and nuanced execution model, necessary for guaranteeing compositional security, makes it esoteric and understood by only seasoned academics. 
In this work we explore UC as a software development tool for distributed protocols through the following research questions:
\begin{enumerate}[label=(RQ\arabic*).,leftmargin=*]
\item Can we use UC as a development framework and capture, or take advantage of, the myriad benefits but through informal analysis?
\item Can we adapt existing techniques for engineering and analysis to the UC setting, and can our modelling provide insight into liveness analysis?
\end{enumerate}
Our belief is that the UC as a development framework is uniquely suited to the asynchronous distributed systems setting, and that alond with our new proposed model for capturing asynchronous network assumption we can make protocols simpler to define, easier to analyze, and allow fundamental components of modern protocols to be realized.
In this work, we propose a new model for asyncronous modelling, with eventual delivery, that greatly improves upon existing definitions that unnecessarily constrain protocol design or make testing more cumbersome.
We implement a fuzz testing mechanism to generate environments and adversaries for testing protocols, and we believe that fuzzing and the UC security definition are a strong match that complement each other well in an engineering setting. 


%\item Is UC suitable and practical as a development framework rather than only a theoretical one?
%    \begin{itemize}
%        \item [(i)] Can existing UC models/techniques be improved for easy of development?
%        \item [(ii)] What are the advantages of using UC for development?
%    \end{itemize}
%\item Is UC compatible with existing software analysis techniques?
%    \begin{itemize}
%        \item [(i)] Does the ideal functionality model and UC's polynomial time notion aid in reasoning about liveness in implementations?
%    \end{itemize}
%\todo{Hypotheses: why UC for async protocols and distributed systems are where this matters the most}
%
%\todo{maybe something along these lines: good as a dev framework for analyzing security and better researcher tooling for analyzing definitions without cumbersome extra work}.

There is a large amount of exsisting literature proposing programming language (PL) and formal verification tools for expressing UC security in limited, but useful ways~\cite{.}.
Contrary to our goal, working with new process calculi, a new domain-specific language, or a proving framework do little to make UC more accessible to non-cryptography researchers because 
\begin{enumerate}
\item Niche programming languages aren't well-suited to production environments and add to the already high learning curve.
\item The added obligations of using PL machinery for mechanizing proofs can add significant work for researchers as well~\cite{ironfleet,easycryptuc} \plan{easycrypt requires a whole new method of communication that makes translating definitions annoying} \todo{saying ``can add burden'' is an unproven claim but maybe still okay?}
\end{enumerate}

For researchers, software artefacts are a crucial for establishing more precise definitions that a broader audience can interact with, resuse, and rigorously test. 
Engineering aside, opening research up to broader falsiability of definitions/proofs is important.
For software engineers, there is a clear advanage to implementing code that matches academic definitions, the ideal functionality models provides a clear interface (specification, adversarial capabilities, and security guarantees) for software modules, and a UC environment facilitates more sophisticated protocol analysis because of its exposure to both honest party input/output and adversarial action.\todo{the point is along the lines mentioned that both scheduling and inputs/outputs allow more intelligent choice of actions for testing more interesting conditions...}
Simply put, UC is an efficient \todo{efficient?} harness for developing and testing protocos under byzantine conditions.
Furthremore, maintaining a symmetry between paper definitions and the resulting implementation solidifies the validity of existing security proofs.

\todo{maybe mention mainstream language earlier}
In order to address our research questions, and intuition, about UC, we implement it in a mainstream language, Haskell, and apply fuzz testing as our candidate analysis technique to explore UC's suitability as a development framework for distributed protocols.
Fuzz testing is a method of property-based testing that involves generating random inputs and checking output against a spec, and prior work shows that it can be as successful, if not better, than formal approaches like symbolic execution. 
It is widely used in practice and considered to be a vital tool in software testing.
Furthermore, implementing fuzzing is itself an engineering excercise that tests the framework's flexibility. 
Additionally, we propose a new mechanism for capturing an asynchronous network that extends asynchronous message deliver to asynchronous code execution. 
Our mechanism, an asynchronous wrapper, allows ITMs to schedule code blocks whose execution is controlled by the adversary and uses the new import mechanism for polynomial time to achieve eventual delivery~\footnote{The import mechanism was devised to overcome problems with previous versions of polytime like the ``length-of-input'' notion, and, as far as we know, we are the first to use it in this way}.
Moving away from traditional definitions that only work with messages, \emph{eventually} executing code blocks massively simplifies UC definitions and is an abstraction familiar to software engineers in other programming languages.
\plan{In fact, we posit that there is significant room for innovation on similar conventional UC-isms.}



We validate this vision for UC by implementing it in a mainsteam language and studying its compatibility with existing development practices. 
\todo{sopped edit here, te rest is not edited:} This implementation realizes the ITM computation model, and provides type checking of channel interfaces between module though we envision more descriptive type systems can be applied to this task.
We push modular and programming-inspired UC designs further by providing a new abstraction for realizing asynchronous, and other arbitrary, networks that both greatly simplifies paper-and-pencil definitions/proofs and an \emph{asynchronous code} abstraction familiar to programmers.
Finally, we employ fuzz testing, a critically important and highly successful testing strategy in modern software engineering, to our own implementations of canonical and modern byzantine agreement protocols and showcase
\begin{itemize}
\item the UC framework especially lends itself to fuzz testing by reducing complex distributed systems to a set of simple protocol and adversarial interfaces that greatly reduce the input space to be searched
\item the real/ideal paradigm already provides a built-in specification, the ideal functionality, of the inteded protocol to test protocols properties against
\item our novel design of asynchronous computing/networking \todo{something something}
\end{itemize}

Rough notes for the paragrapph. 
We implement bracha, ben-or, aba and inject faults into them. show how simple fuzzers that don't target specific vulnerabilities can find bugs that violate agreement/safety/etf
the better approach might be to idenftify only the set of bugs that would induce failures in safety and then say that those can be identified
but what about simpler bugs? that would require more meaningful testing but not what UC is good fr
existing fuzz testing is already good for bugs in single compiled progra like a single protocol running in isolation, so we don't think of finding those
but finding those of a distributed nature


Rather than bridge the gap between cryptography reserachers and protocol implementers, these approaches aid validation but accept and embrace the complexity of the framework.
Ultimately, the advantages of the proving framework, and the paper proofs that rely on it, are lost because of code that completely departs from them. 




%  Universal Composability (UC)~\cite{canettiUC} is the leading framework for defining security properties of cryptographic protocols.
%  It is considered the strongest definitional model since it guarantees the security properties hold even when the protocol is arbitrarily composed with
%  multiple concurrently-executing sessions of other protocol.
%  UC has gained popularity for analyzing cryptographic protocols due to its \emph{ideal world/real world} simulation mechanism.
%  In contrast to game-based cryptography where security properties are defined via attack games,
%  UC defines the \emph{ideal functionality}, a trusted third party that serves as the \emph{protocol specification}.
%  A core feature of the frameowk is its modularity where complex protocols are defined in terms of simple, ideal functionality building blocks that are secure by definition. 
%  A major drawback of UC is that security proofs can be quite complicated and difficult to analyze. 
%  Many related works \cite{ilc, easyuc, ipdl, etc} attempt to formalize UC security through a new programming language or defining UC security in an existing formal verification lanuage, and,  
%  although useful, such tools frequently never make their way to software engineering practice because
%  1. niche programming languages aren't suited to large scale development and can be difficult to use, and 2. the added proof obligations on the programmer can be extensive~\cite{ironfleet}.
%  Utimately, UC-secure prtocols end up being implemented in software frameworks that do not replicate UC, and, therefore, my invalidate on-paper proofs without further security proofs of the code.
%  
%  We address this gap in UC-driven software develoment by exploring how inforal security analysis of UC definitons, in our implementation of UC, can identify, and aid in eliminating, security vulnerabilities.
%  A key controbution of our software development framework for UC is proposing a noval new abstraction for capturing network assumptions. Our abstraction makes use of the novel import mechanism 
%  for polynomial time and fits nicely as a software abstraction. Our implementation and network model are, to the best of our knowledge, the first concretiziations of the import mechanism in this way.
%  Prior attempts at modelling asynchrnous networks, for example, focus primarily on adversarial delay of messages between parites. Such notions can require
%  protocols to encode signficant model-specific behavior which clutters functionalitiy (and protocol) definitions, places unecessary restrictions on protocol design, and is counter-productive for modular and reusable code. 
%  Out abstraction, on the other hand, acts are a wrapper around ITMs and offers a notion of \emph{asynchronous computation} in a way that is UC-compatible and firs well within a software framework. 
%  Not only is it natural for software development, but it also reduces functionality and protocol code to be almost model-agnostic. 
%  We use our network model of computation to focus solely on modeling and analzing distributed protocols in this work.
%  UC is most notably a framework for cryptographic protocols, however, in recent years the emergence of decentralized systems has renewed focus on modelling the security of asynchronous byzantine networks in UC~\cite{many,cit,ations}. 
%  Decentralized, namely blockchain, systems are highly modular with many protocols sharing state in unexpected ways and relying on numerous shared distrbuted sub protocols.
%  Naturally, compositional security in UC is ideal for capturing such protocols. 
%  
%  We opt for fuzz testing, by generating environments, as our analysis tool for three important reasons. First, numerous prior work has demonstrated the success of fuzz testing at identifyin software bugs. 
%  Some work suggests fuzzing is comparable in success to even formal approach such as symbolic execution. 
%  Second, the UC framework lends itself to compact definitions that compose through ideal functionalities making the input space for protocol parties and adversaries much smaller. 
%  Combined with our simple network model, UC modularity makes it easier for generated environmenst to explore more of the state space for a particular protocol or simulator proof. \todo{is this setting us up with an obligation to prove this statement with some coverage testing?}
%  Third, the real/ideal paradigm, and the ideal functionality, provide a built-in specification against which protocols can be tested and a method for comparing the two (the UC experiment). \todo{this last one is the least good the point is that we don't have to define state machines and added spec on top of a protocol, they should already exist from on-paper definitions it isn't an additional obligation to the programmer when using haskell saucy fuzzing.}
%  
%  Among the few related works that apply fuzzing to distributed systems, the work by Jepsen goes so far as to apply their methdology to a decentralized byzantine consensus protocol called Tendermint.
%  Jepsen deploys compiled Tenderming binaries and tests that operations on a distributed database are linearizable under various network conditions and limited byzantine behavior. 
%  As they admit in their results, the byzantine behavior that they capture is limited to replicated simple scenarios signing keys for multiple nodes. Designing a ful byzantine node for Tendermint is a considerable engineering effort.
%  Part of the hurdle is that testing a monolothic application like the Tendermint binary requires instrumenting and implementing every sub-component in the whole protocol.
%  Conversely, it is not possible, within \us, to test secrity under clock skews or race conditions in multi-threaded handling of network messages like Jepsen is able todo.
%  Hoever, this isn't a limitation of \us, but highlights a key distinction between us and works like Jepsen. \us is a \emph{development framework} rather than only a testing framework.
%  An application like Tendermint, implemented in \us, ensures that sub-components like network handling and clock timing are implemented and tested in isolation.
%  As mentioned in the previous paragraph, this makes allows us to test race conditions, should they arise, and capture byzantine complicated byzantine behaviort that Jepsen does not. 
%  \todo{feels like the point is there but not stated clearly enough. I'm trying to relate to the point of reduced input space from the previous paragraph to talk about why byzantine modelling is easy in \us and that not being able to do clock-skew type testing is a consequencer of Jepsen not being a development framework and having to work with existing monolithic binaries.}

\subsection{Below this is just notes}

\us is a not only a testing framework but a \emph{development framework} where subcomponents and sub protocols are created and tested in isolation.

Combined with paper and pencil proofs, we can reply on the composition theorem to test more complex protocols like Tendermint without worrying about the full code stack.
For example, even though \us can doesn't allow testing of race conditions resulting from multi-threaded handling of network messages 

our framework ensures that such sub-components of Tenderming are created and tested
within UC and composed correctly. 

Jepsen fuzz test a compiled binary for Tendermint and check that updates to a distributed database are linearizable under various network conditions and some byzantine behavior.



fuzz testing is a proven technique even when compared to formal analysis tool. this shows promise as a simple informal tool for protocol analysis
compared to things like jepsen running and testing protocols is much easier without any of the engineering effort require because of the subtle ways in which UC is designed to mimic a realistic computing environment and network
fuzzing byzantine messages is easier with UC for a few reasons:
* the simple interface for adversarial behavior makes it easy to play with message ordering and deliver / dropping messages
* the ideal functionality abstraction removes sub-protocol detail making the space of byzantine messgaes much smaller / manageable for fuzz testing

this leads into another point about comparing with jepsen. they test existing compiled binaries and so end up testing the full stack of code as part of their testing
they can test race conditions in how messages are received, for exampe, and standalone UC fuzz testing can not replicate that
but this is precisely where UC shines: not just testing code but developing it within the UC framework all such sub-protocols are tested and designed individually and larger, composed protocols only testing teir behavior with the ideal functionality model 



We address the state of software development around UC by exploring the extent to which informal security analysis of UC definitions, in our UC implementation can identify, and aid in elminiating, security vulnerabilities such as safety, correctness, and liveness in distributed systems .\todo{this first line needs to be better}.  
A key contribution of our software development framework around UC begins with proposing a novel abstraction for capturing different network models.
Prior attempts to capture, for example, asynchronous communication focus primarily on adversarial delay of messages between parties. 
Such notions can require protocols to encode significant model-specifi behavior in their definition which lutters definitions, places unecessary restrictions on protocol design, and is counter-productive for modular and reusable code. 
Our abstraction, on the other hand, acts as a wrapper around ITMs and extends the abstraction to asynchronous \emph{computation}: adverasrially delayed code rather than messages.  
Not only is this abstraction more natural for a software setting, but it also reduces functionalities and protocols to become almost model-agnostic in their definition. 
For asynchronous networks we dub our construction the \emph{asynchronous wrapper}. 
It uses the import mechanism introduced in UC to provide \emph{eventual} deliver guarantees.
To the best of our knowledge, it is the first concretization of the import mechanism with eventual delivery. 



\todo{a statement wrapping all this up in a key takeaway and positive result of this work in the context of the state of UC}.
