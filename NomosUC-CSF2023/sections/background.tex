\subsection{Universal Composability}
The Universal Composability (UC) framework~\cite{canettiUC} is a leading framework for defining security in cryptographic protocols.
UC is based on the real/ideal paradigm, where security is defined as a relation between two systems: the real world, which features the protocol $\pi$ under analysis, as well as an arbitrary adversary \A that controls corrupt parties; and the ideal world, which mainly comprises ideal functionality \F, a trusted third party that carries out the desired task directly.
A reason ideal functionalities have become a popular alternative to traditional game-based definitions is that a security definition consists of a single program for one trusted party, rather than a collection of properties pertaining to several (potentially faulty) parties.
%Figure~\ref{fig:}

To summarize the ideal/real security relation, roughly we need to show ``any attack in the real world is also exhibited by the ideal functionality.'' This means constructing a simulator \Sim that plays the role of adversary in the ideal world.
What makes UC the strongest among ideal/real frameworks is that the inputs of honest parties are chosen adaptively by the distinguishing environment \Z, which can also communicate with the adversary and interleave its interactions with honest parties.
This adversary model leads to a flexible approach to composition, which we'll say more about shortly.
More formally, the security definition says that a protocol $\pi$ realizes an ideal functionality $\F$
if for every adversary $\A$, we can construct a simulator $\Sim$, such that the real and ideal world are indistinguishable for any environment \Z:
\begin{equation}
  \label{eqn:emulation}
  \forall \A \; \exists \Sim \; \forall \Z \; \; \msf{execUC} \; \Z \, \idealP \, \F \, \Sim \sim \msf{execUC} \; \Z \, \pi \, \F_0 \, \A
\end{equation}
Here $\idealP$ is the ideal protocol that simply passes inputs between environment and ideal functionality, and $\F_0$ takes the place of the ideal functionality in the real world, and is typically used to express network assumptions or assumed primitives the current protocol relies on.
The \msf{execUC} defines the UC execution experiment that hooks up the channels to the processes in its arguments.
Importantly, the number of protocol parties in UC is entirely dynamic and chosen at runtime by the environment. 
Defining \msf{execUC} in our core calculus, and especially reconciling its the dynamic nature with the static guarantees of our type system will be the central technical challenge we'll tackle later.

\paragraph{Composition Notation}
The UC framework is designed to encourage a highly compositional and modular design approach, where we analyze single-instance protocols in isolation, then apply generic composition operators to build more complex systems.
Encoding the standard theory of UC composition in our framework is one of the main ways we validate the expressiveness of our language design.
Here we summarize the main composition theorems using category notation, where objects are functionalities and arrows are protocols.
First, if $\pi$ realizes $\F$ in the $\F_0$ hybrid world according to the definition above, we write:
\[
	\F_1 \xrightarrow{\pi} \F_2
        \]
This means in the real world $\pi$ makes use of a single instance of $\F_1$, and the ideal world consists of a single instance of $\F_2$.
The first composition theorem states that this relation is transitive, where $\rho \circ \pi$ is a generic composition operator that combines two protocols by connecting the $\rho \Leftarrow \F$ channels in $\rho$ to the $\pi \Leftarrow \Z$ channel of $F$. That is, when protocol $\rho$ communicates with its ideal functionality, it is is relayed as subroutine input to $\pi$.
\begin{theorem}[Composition]\label{thm:singlecomp}
\begin{mathpar}
\inferrule*[right=single-compose]
{
	\F_1 \xrightarrow{\pi} \F_2 \semi \F_2 \xrightarrow{\rho} \F_3 \\
}
{
	\F_1 \xrightarrow{\rho \circ \pi} \F_3
}
\end{mathpar}
\end{theorem}
To prove this theorem requires constructing a straightforward simulator that combines the underlying simulators of $\pi$ and $\rho$, and the complete security reduction involves translating a distinguisher $Z$ for the combined protocol $\rho \circ \pi$ to a distinguisher $Z^*$ for either $\pi$ or $\rho$ individually.
Although the proof is straightforward, the precise statement of it in our framework serves as good validation for the expressiveness of our framework: our theorem and proof are parametric in the session type of the protocol, i.e., the theorem places no restrictions on the communication pattern used by the underlying protocol and functionalities.

The next generic operation is the multi-session extension of $\F$, denoted $!\F$, which provides $\pi$ with an arbitrary number of instances of $\F$, each tagged with a separate \textsf{sid} (for \emph{session identifier}).
Here is a central aspect of UC's flexibility, that the environment gets to determine at runtime the exact number and values of \textsf{sid}'s, with no static bound required.
The Universal Composition theorem says that composition even holds in this setting, which we state as
$!\F_1 \xrightarrow{\pi} \F_2$, $!\F_2 \xrightarrow{\phi} \F_3 \implies !\F_1 \xrightarrow{\phi \circ !\pi} F_3$.
This theorem is essential to the appeal of UC as a framework because it encourages simple analysis of a single protocol in isolation (the proof that $\pi$ realizes one instance of $\F_2$), which is then safe to use in protocols like $\phi$ that rely on multiple concurrently-running subsessions of it.

\paragraph{Universal Composability and ITMs}
The UC framework is defined on top of a communication model called interactive turing machines (ITMs), in which multiple Turing-complete processes run concurrently in a system and communicate by passing messages over channels~\cite{canettiUC}.
Although the Turing-complete computations can be instantiated in any reasonable core calculus, the approach to message passing in ITMs has some essential but subtle restrictions.
In order to do cryptographic analysis, we need to make reductions to (ordinary sequential) probabilistic polynomial time computations (PPTs).
This rules out, for example, the ordinary semantics of $\pi$-calculus, which introduces unbounded non-determinism with the possible scheduler choices.

Our approach, following ILC~\cite{ilc}, is to encode the ITMs framework as faithfully as possible.
%This is because the final step in a UC proof is to show that a distinguishing environment Z can be leveraged to construct a polynomial time solution to a hard problem like Discrete Log.
The basic rule that ITMs follow is that only one process is active at a given time. 
Specifically whenever a process writes to one of its outgoing channels, the unique process that holds the read end of that channel is immediately activated next.
In this way the message scheduling is essentially deterministic so it can be easily simulated by a sequential computation.
This discipline means that modeling inherently non-deterministic phenomena, like network schedulers, requires us to explicitly offer choices to an adversary process defined in our model.

Even having established the message pattern, it is still not straightforward to define a notion of polynomial runtime for ITM systems.
Looking at the order of quantifiers in the UC emulation definition from Relation~\ref{eqn:emulation}, we need a way to make local judgments about each $\A$, $\Z$, $\pi$, and $\F$ individual, and conclude that the entire $\msf{execUC} \; \Z \; \pi \; \A \; \F$ experiment overall is polynomial time as a result.
We follow Canetti's approach~\cite{canettiUC}, which is to keep track at runtime of quantity called ``import tokens'' and assign a runtime budget based on these.
These tokens can be passed among the processes along with the messages sent on each tape, but the total amount of tokens must be conserved (neither created nor destroyed), and locally each process cannot take more steps than (a polynomial of) the amount of import tokens it has stored.
Somewhat more formally, we say $P$ is a \emph{locally polynomial time process} if for \emph{any} evaluation context $e[\_]$, at any step $t$ during its execution,
\[
\#\textsf{stepsTaken}(e[P])_{t} \le T(n_{\textsf{in}} - n_{\textsf{out}})
\]
where $n_{\textsf{in}}$ is the total number of import tokens received by $P$ and $n_{\textsf{out}}$ is the total number of tokens $P$ has sent, and $T$ is an arbitrary polynomial.
This immediately ensures that if the system starts out with a total number of tokens bounded in the security parameter $k$, then the overall number of steps taken by any of the processes in the system is also bounded in $k$.
The arbitrary polynomial $T$ serves as a slack parameter that allows, for example, the emulation of a universal turing machine program (which may incur up to quadratic overhead).
Our approach, described in Section~\ref{sec:basic}, is to encode this notion directly into the type system, by tracking import tokens and statically enforcing this polynomial runtime constraint.

