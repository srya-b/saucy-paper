\paragraph*{\textbf{Import Tokens}}
A defining aspect of NomosUC is the representation of import tokens in the type system.
This enables a static reasoning of the import mechanism in NomosUC.
To this end, we introduce a novel token context $\Tokens$
in the process typing judgment to denote the real and virtual tokens.
This context contains the information on the total and current tokens
of each type and the \emph{security parameter}.
Before we explain the token context we first motivate the need for virtual tokens
It is a common technique in UC, especially in simulators, to internally run, or simulate, 
the code of other ITIs. In NomosUC, we wish to enable the same sandbox running of processes,
but its channels may have import requirements. It doesn't make sense to
send real import to such a process, because, intuitively the internal process should use the
import and, therefore, potential available to the ``host'' process~\footnote{As far as resource-contraints go, simulating a process should be no different from natively executing its code.}. Therefore, in 
order to satisfy the types of internally simulated processes we introduce a virtual 
tokens construction. 
By default, every process contains a unique real token type $K_0$
and corresponding number of total and current tokens $n$ and $n'$ resp.\
denoted by $K_0 \hookrightarrow (n, n')$.
There is no mechanism to create a real token; they can only be passed on to
a process during its creation, or be exchanged between processes during communication.
Virtual tokens, on the other hand, can be created (under certain conditions,
see below) by a process.
However, all tokens follow a \emph{token hierarchy}: $K_0 \to K_1 \to K_2 \to \ldots K_m$
such that we can only use tokens of type $K_i$ to withdraw tokens of type
$K_{i+1}$~\footnote{ITIs in UC can have arbitrary simulation depth, i.e. a process simulates another process which simulates another process. Despite this, we can statically define the token heirarchy because it is statically known the maximum simulation depth of any process in the UC execution.}.
In addition, we use a global function $\GlobalF$ as the connection
rate between two successive token types.

To maintain well-typedness of a process, an implicit side condition is
that the token context must always be \emph{valid}.
This involves ensuring that if the context contains $m'$ current tokens of type
$K_i$, it can only contain at most $\GlobalF(m,k)$ total tokens of type
$K_{i+1}$. The inductive rules for validity of a token context are below.
\begin{mathpar}
  \infer
  {K_0 \hookrightarrow (t_0, t_0') \;\; \m{valid}}
  {}
  \and
  \infer
  {k \and \Tokens, K_{i+1} \hookrightarrow (t_{i+1}, t_{i+1}')\;\; \m{valid}}
  {\Tokens\;\; \m{valid} \and
  K_{i} \hookrightarrow (t_i, t_i') \in \Tokens \and
  t_{i+1} \leq \GlobalF(t_i',k)}
\end{mathpar}
Since validity of a token context is a side condition, we mandate
that it is implicitly satisfied by all the process typing rules
presented in our paper.
From an implementation point-of-view, this validity check only
needs to be performed when the token context changes (in the
rules that follow).

As a first step in introducing program notation for import tokens, we need 
syntax for creating new tokens of a given token type.
We call this construct $\m{withdrawToken} \; K_i \; n \; K_{i+1}$.
\begin{mathpar}
  \inferrule*[right=$\m{tok}$]
  {k \semi \Tokens, K_{i+1} \hookrightarrow (t_{i+1} + n, t_{i+1}' + n) \semi
  \Psi \semi\wt, \D \entailpot{\B{q}}{\B{q'}} P :: (x : A)}
  {k \semi \Tokens, K_{i+1} \hookrightarrow (t_{i+1}, t_{i+1}') \semi \Psi \semi \wt, \D \entailpot{\B{q}}{\B{q'}} \hspace{4em} \\
    \hspace{5em}\m{withdrawToken} \; K_i \; n\; K_{i+1}  \semi P :: (x : A)}
\end{mathpar}
The above construct generates $n$ new tokens of type $K_{i+1}$ and adds
them to both the total and current count for $K_{i+1}$ in the token
context $\Tokens$.
The implicit side condition of the validity of the token context ensures
that $t_{i+1} + n \leq \GlobalF(t_i',k)$ where $K_i \hookrightarrow (t_i, t_i') \in \Tokens$.
If this side condition fails, the above construct would fail to typecheck.

In addition, we also introduce two dual constructs for exchanging tokens
between processes.
To this end, we first introduce two new type constructors.
\begin{center}
\begin{minipage}{0cm}
\begin{tabbing}
$A ::= \ldots \mid \tpaypot{A}{r : K} \mid \tgetpot{A}{r : K}$
\end{tabbing}
\end{minipage}
\end{center}
The provider of $x : \tgetpot{A}{r : K}$ is required to receive
$r$ import tokens of type $K$ from the client using the construct
$\eget{x}{r : K}$. Dually, the client needs to pay this import
using the construct $\epay{x}{r : K}$.
The corresponding typing rules are
\begin{mathpar}
  \footnotesize
  \infer[\getpot R]
  {k \semi \Tokens, K_i \hookrightarrow (t_i, t_i') \semi \Psi \semi \D \entailpot{\B{q}}{\B{q'}} \eget{x}{r : K_i} \semi P ::
  (x : \tgetpot{A}{r : K_i})}
  {k \semi \Tokens, K_i \hookrightarrow (t_i, t_i'+r) \semi \Psi \semi \wt, \D \entailpot{\B{q}}{\B{q'}} P :: (x : A)}
  %
  \and
  %
  \infer[\getpot L]
  {k \semi \Tokens, K_i \hookrightarrow (t_i, t_i'+r) \semi \Psi \semi \wt, \D, (x : \tgetpot{A}{r : K_i}) \entailpot{\B{q}}{\B{q'}}
  \epay{x}{r : K_i} \semi P :: (z : C)}
  {k \semi \Tokens, K_i \hookrightarrow (t_i, t_i') \semi \Psi \semi \D, (x : A) \entailpot{\B{q}}{\B{q'}} P :: (z : C)}
\end{mathpar}
In the rule $\getpot R$, process $P$ storing $(t_i, t_i')$ import tokens of type $K_i$
receives $r$ additional $K_i$ tokens adding it to the current token counter, thus
the continuation executes with $(t_i, t_i'+r)$ tokens of type $K_i$.
Note that validity of token context is trivially satisfied in this case since the
process is gaining import tokens.
%
In the dual rule $\getpot L$, a process containing $(t_i, t_i'+r)$ tokens of type $K_i$
pays $r$ units along channel $x$ leaving $(t_i, t_i')$ import tokens of type $K_i$ with
the continuation.
In this case, the validity of the token context establishes that $t_{i+1} \leq \GlobalF(t_i',k)$,
a condition that is necessary for successful typechecking.
The typing rules for the dual constructor $\tpaypot{A}{r : K}$
are the exact inverse.
Similar to prior rules, the sender transfers the write token $\wt$
along with the potential to the receiver.

The need for virtual tokens in UC arises because machines often simulate
other machines as part of their construction. The program notation for \msf{withdrawToken}
does not require an inverse to exchange tokens \textit{back} from type $K'$ to $K$.
The reason is that virtual tokens only exist to allow re-use of existing processes 
and satisfy their types. Type $K$ tokens are not deducted when new ones of type $K'$ 
are created is because, in reality, siulating a process by calling it or simply running
its code natively should be equivalent in cost. Therefore, there is also no need to 
include an inverse of \msf{withdrawToken} which exchanges from $K'$ to $K$.

\paragraph*{\textbf{Potential}}
The main purpose of import tokens is to bound the number of execution steps of ITMs.
We achieve that purpose in NomosUC by introducing the notion of \emph{potential}.
Potential is an abstract quantity represented by a natural number stored
within each process.
To take an execution step, a process consumes \emph{one} unit of potential.
Therefore, the total potential stored in a process upper bounds the total
number of execution steps that will ever be taken by the process.
Furthermore, potential is represented syntactically, thus providing a
static upper bound on the execution cost.
Since execution cost needs to eventually connect to the import tokens, all
we need is a mechanism to generate potential using import tokens.
To this end, we introduce a novel construct $\m{genPot} \; r$.
\begin{mathpar}
  \inferrule*[right=$\m{pot}$]
  {q+r \leq \GlobalF(t_{\depth}',k) \and K_{\depth} \hookrightarrow (t_{\depth}, t_{\depth}') \in \Tokens \\\\
  k \semi \Tokens \semi \Psi \semi \wt, \D \entailpot{q+r}{q'+r} P :: (x : A)}
  {k \semi \Tokens \semi \Psi \semi \wt, \D \entailpot{q}{q'} \m{genPot} \; r \semi P :: (x : A)}
\end{mathpar}
A process initially storing $(q, q')$ potential units generates $r$ potential so that
the continuation contains $(q+r, q'+r)$ potential units.
Note, however, that the maximum potential allowed is bounded by the number of import tokens
a process contains.
To this end, we introduce a \emph{token depth}: $\depth$ that signifies the number of token
types that exist in the token hierarchy.
Thus, when generating potential, the typechecker verifies that the total new potential (i.e., $q+r$)
is bounded by $\GlobalF(t_{\depth}',k)$ where $(t_{\depth}, t_{\depth}')$ is the number of tokens
of type $K_{\depth}$, the highest token in the hierarchy.

The purpose of introducing potential into NomosUC is to bound the
number of execution steps.
Therefore, we introduce the $\etick{r}$ construct that consumes $r$
potential from the stored process potential $q$, and the continuation remains with
$p = q-r$ units, as described in the rule below.
\begin{mathpar}
  \footnotesize
  \infer[\m{tick}]
  {k \semi \Tokens \semi \Psi \semi \wt, \D \entailpot{q}{q'+r} \etick{r} \semi P :: (x : A)}
  {k \semi \Tokens \semi \Psi \semi \wt, \D \entailpot{q}{q'} P :: (x : A)}
\end{mathpar}
NomosUC is equipped with a cost instrumentation engine that automatically
inserts a $\etick{1}$ construct before each primitive operation.
This enables us to simulate the cost model that counts the total number of
execution steps.
However, since ticks are not tied directly to the type system, the programmer
can modify the cost model to only count the resource they are interested in
(e.g., message exchange, process spawns, etc.).

% \begin{mathpar}
%   \D_1 \equiv_Z \D_2 \\
%   \D \overset{(import, potential, cost)}{\vDash} P :: \D' \\
%   A \equiv B \\
%   \infer[]
%   {\vars \vdash \D_1, (x : A) \equiv \D_2, (x : B)}
%   {\vars \vdash \D_1 \equiv \D_2 \and \vars \vdash A \equiv B}
% \end{mathpar}

\paragraph*{\textbf{Shared Channels}}
Until now, we have only described the linear fragment of session types
in Nomos.
Unfortunately, this fragment imposes a strong restriction on programs.
The only provision to spawn new processes is when a parent process creates a new
child process, and uses an exclusive linear channel to communicate with the child.
Thus, any two processes connected by a channel inherently maintain this parent-child
relationship.
Intuitively, this leads to a linear tree-like hierarchy among the processes,
thus preventing a cycle in the process graph.

Unfortunately, this restriction precludes practical programming scenarios
where process topologies indeed have a cyclic dependency (e.g. ring networks,
dining philosophers, etc.).
Recognizing this limitation, Balzer et al.~\cite{balzer2017manifest} proposed
a \emph{shared} extension of session types that allows arbitrary process topologies.
The types are extended as follows:
\begin{center}
\begin{minipage}{0cm}
\begin{tabbing}
$A_L ::= \down A_S \mid \ldots \text{(all linear types $A$ so far)}\ldots$\\
$A_S ::= \up A_L$
\end{tabbing}
\end{minipage}
\end{center}
We have found this extension exceedingly helpful in the design and implementation
of cryptographic protocols.

Shared session types impose an \emph{acquire-release} discipline on processes; 
a client must acquire the channel offered by a shared process to interact with it
and must release this channel after the interaction.
The corresponding typing rules are
\begin{mathpar}
  \footnotesize
  \infer[\up L]
  {k \semi \Tokens \semi \Psi \semi \wt, \D, (x : \up A_L)
  \entailpot{q}{q'} \eacquire{y}{x} \semi Q :: (z : C)}
  {k \semi \Tokens \semi \Psi \semi \D, (y : A_L)
  \entailpot{q}{q'} Q :: (z : C)}
  %
  \and
  %
  \infer[\up R]
  {k \semi \Tokens \semi \Psi \semi \D \entailpot{q}{q'}
  \eaccept{y}{x} \semi P :: (x : \up A_L)}
  {k \semi \Tokens \semi \Psi \semi \wt, \D \entailpot{q}{q'} P :: (y : A_L)}
\end{mathpar}
The $\up L$ rule describes a client acquiring a shared channel $x$
and obtaining a private linear channel $y$ along which it can communicate
with the corresponding acquired process.
Correspondingly, the $\up R$ rule describes the shared process
accepting the acquire request and creating the fresh linear channel $y$.
The release-detach rules corresponding to the $\down$ type constructor
are exact dual of acquire-accept.

An important caveat here is that shared channels can introduce non-determinism
in the semantics.
The only source of non-determinism is that a shared process can latch on to
any of the acquiring clients.
To address this problem, we require that the acquiring client \emph{possess
the write token}.
Since write tokens are treated as a linear quantity, only one of the client can
possess it enabling only that process to acquire the shared channel.
Remarkably, this write token can resolve both read and write non-determinism
due to linearity of the channels.


\paragraph*{\textbf{Process Definitions and Sandboxing}}
Process definitions have the form
$\Psi \semi \D \entailpot{q}{q'} f\{\Tokens\} :: (x : A) = P$ where $f$
is the name of the process and $P$ its definition.
We parameterize the process $f$ with the number and type of
real tokens it would need.
All definitions are collected in a fixed global process signature $\Sg$.
Also, since process definitions are mutually recursive, it is required that
for every process in the signature is well-typed w.r.t. $\Sg$.
A new instance of a defined process $f$ can be spawned with
the expression $\procdef{f\{\Tokens\}}{\overline{y}}{x} \semi Q$
where $\overline{y}$ is a sequence of variables matching the
antecedents $\Psi$ and $\D$.
Sometimes a process invocation is a \emph{tail call}, written without
a continuation as $\procdef{f\{\Tokens\}}{\overline{y}}{x}$.
This is a short-hand for
$\procdef{f\{\Tokens\}}{\overline{y}}{x'} \semi \fwd{x}{x'}$ for a
fresh variable $x'$, that is, a fresh channel is created and
immediately identified with $x$.

An important note here is that NomosUC allows executing processes in
a \emph{sandbox}.
Therefore, a process invocation can either be \emph{regular} or in a
\emph{sandbox}.
Syntactically, we use the same term for both but the two invocations
are distinguished via the token type passed into the call.
For a regular call, the parent process passes in a real token type,
while for a sandboxed call, a virtual token type is passed in.
We have a similar distinction for $\m{pay}$ and $\m{get}$ expressions:
if a real token is passed into these terms, it's a regular token
exchange; if a virtual token is passed in, it's a sandboxed $\m{pay}$
and $\m{get}$.

\subsection{Preservation and Progress}
The main type safety theorems that exhibit the deep connection between our type
system and the operational semantics are the usual \emph{type
preservation} and \emph{progress}, sometimes called \emph{session
fidelity} and \emph{deadlock freedom}, respectively.

To exhibit these theorems, we first need to introduce semantic objects
$\proc{c}{w, P}$ and $\msg{c}{w, M}$.
The former (resp. latter) denotes a process (resp. message) executing
expression $P$ (resp. $M$) offering channel $c$ and having performed
work $w$ so far.
The work counter keeps track of execution steps taken by a process,
giving rise to the following semantics rule:
\begin{tabbing}
  $(\m{tick}) : \proc{c}{w, \etick{r} \semi P} \step \proc{c}{w+r, P}$
\end{tabbing}
A multiset of such semantic objects communicating with each other
is known as a \emph{configuration}.
A configuration is typed w.r.t. a signature providing the type declaration
of each process.
A signature $\Sg$ is \emph{well formed} if
(a) every type definition $V = A_V$ is \emph{contractive},
and (b) every process definition
$\Psi \semi \D \vdash f \{\Tokens\} = P :: (x : A)$ in $\Sg$
is well typed according to the process typing judgment, i.e.
$\Tokens \semi \Psi \semi \D \vdash P :: (x : A)$.
 
A key question then is how to type these configurations.
Since they consist of both processes and messages, they
both \emph{use} and \emph{provide} a collection of channels.
Another goal with the type safety theorems is to establish a connection
between the statically determined import tokens of a process,
its total potential, and the dynamically evolving work counters
that account for the total number of execution steps.
We use the following judgment to type a configuration.
\[
\D_1 \overset{(T, Q)}{\underset{W}{\vDash}} \config :: \D_2
\]
It states that the configuration $\config$
uses the channels in the context $\D_1$ and provides the channels in
the context $\D_2$.
In addition, $T$ and $Q$denote the total number of real tokens
potential contained in a configuration.
Similarly, $W$ denotes the total work performed by a configuration.
All these quantities are computed by adding the individual tokens,
potential, and work of each semantic object.
\begin{figure}[t]
\begin{mathpar}
\infer[\m{empty}]
{\D \overset{(0, 0)}{\underset{0}{\vDash}} (\cdot) :: \D}
{}
\and
\infer[\m{compose}]
{\D_0 \overset{(T_1+T_2, Q_1+Q_2)}{\underset{W_1+W_2}{\vDash}} (\config_1 \; \config_2) :: \D_2}
{\D_0 \overset{(T_1, Q_1)}{\underset{W_1}{\vDash}} \config_1 :: \D_1 \qquad
\D_1 \overset{(T_2, Q_2)}{\underset{W_2}{\vDash}} \config_2 :: \D_2}
\and
\infer[\m{proc}]
{\D, \D_1 \overset{(t, q)}{\underset{w}{\vDash}} \proc{c}{w, P} :: (\D, (c : A) )}
{\Tokens, K_0 \hookrightarrow t \semi \cdot \semi \D_1 \entailpot{q} P :: (c : A)}
\and
\infer[\m{msg}]
{\D, \D_1 \overset{(t, q)}{\underset{w}{\vDash}} \msg{c}{w, M} :: (\D, (c : A) )}
{\Tokens, K_0 \hookrightarrow t \semi \cdot \semi \D_1 \entailpot{q} M :: (c : A)}
\end{mathpar}
\caption{Typing rules for a configuration}
\label{fig:config_typing}
\end{figure}

The configuration typing judgment is defined using
the rules presented in Figure~\ref{fig:config_typing}.
%
The rule $\m{empty}$ defines that an empty configuration
is well-typed with $(T, Q, W) = (0, 0, 0)$ and uses and
provides the same set of channels.
The $\m{compose}$ rule combines two configurations by canceling out
the common channels and adding the individual tokens, potential, and work.
The $\m{proc}$ rule creates a configuration out of a single process
and uses its tokens, potential, and work as the annotations for the
configuration.
Similarly, the $\m{msg}$ rule creates a configuration out of a single message.

\begin{theorem}[Type Preservation]
\label{thm:preservation}
Suppose we have a well-typed configuration
$\D \overset{(T_1, Q_1)}{\underset{W_1}{\vDash}} \config_1 :: \D'$ such
that there exists a polynomial $\mathfrak{p}$ such that $\mathfrak{p}(T_1) \geq Q_1+W_1$.
If $\config_1 \step \config_2$, then there exist $T_2$, $Q_2$, and $W_2$ such
that $\D \overset{(T_2, Q_2)}{\underset{W_2}{\vDash}} \config_2 :: \D'$,
and $\mathfrak{p}(T_2) \geq Q_2+W_2$.
\end{theorem}
\begin{proof}
  By case analysis on the transition rule, applying inversion to the
  given typing derivation, and then assembling a new derivation of
  $\dc$.
\end{proof}

A process or message is said to be \emph{poised} if it is trying to
communicate along the channel that it provides.  A poised process is
comparable to a value in a sequential language. A configuration is
poised if every process or message in the configuration is poised.
Conceptually, this implies that the configuration is trying to communicate
externally, i.e. along one of the channel it provides.
The progress theorem then shows that either a configuration can take a
step or it is poised.  To prove this I show first that the typing
derivation can be rearranged to go strictly from right to left and
then proceed by induction over this particular derivation.

\begin{theorem}[Global Progress]
\label{thm:progress}
\mbox{}
If $\cdot \overset{(T, Q)}{\underset{W}{\vDash}} \config :: \D$ then either
\begin{enumerate}
\item[(i)] $\config \mapsto \config'$ for some $\config'$, or
\item[(ii)] $\config$ is poised.
\end{enumerate}
\end{theorem}
\begin{proof}
By induction on the right-to-left typing of $\config$ so that either
$\config$ is empty (and therefore poised) or
$\config = (\dc\; \proc{c}{w, P})$ or
$\config = (\dc\; \msg{c}{w, M})$. By induction hypothesis, $\dc$ can
either take a step (and then so can $\config$), or $\dc$ is poised.  In
the latter case, I
analyze the cases for $P$ and $M$, applying multiple steps of
inversion to show that in each
case either $\config$ can take a step or is poised.
\end{proof}


%\subsection{UC Communicators} \label{sec:communicators}
%% all the processes conncted together leads to a cycle of linear channels ==> Z <--> P so here we use a communicator 
%The UC execution connects the protocol to the environment in both directions of communication.
%This poses a technical challenge where, if linear channels are used, the resulting topology contains a cycle of linear channels: the environmtne offers a channel to the wrapper and the wrapper to the environment.
%Such cycles violate type preservation because a client is acquiring its client~\ref{dasnomos}.
%Therefore, we use a message buffers called communicators which offered shared channels that both ends of the communication can use.
%Communicators are used in the main UC execution in Section~\ref{sec:execuc} to connect the main processes together, as well as within the \partywrapper. 
%
%A communicator has a \emph{sender} and a \emph{receiver}. 
%The shared channel offered by the communicator has the following polymorphic session type:
%\begin{tabbing}
%  $\mi{stype} \; \m{comm[K][msg]\{n\}} =$\\
%  \quad $\up \tgetpot{}{n+1: K} \echoice{$\=$\mb{push} : \m{msg} \arrow
%  \down \m{comm[msg]},$\\
%  \>$\mb{pop} : \ichoice{$\=$\mb{yesmsg} : \m{msg} \product \down \tpaypot{}{n: K} \m{comm[msg]},$\\
%  \>\>$\mb{nomsg} : \down \m{comm[msg]} }}$
%\end{tabbing}
%
%One illustration of the use of shared session types is a \emph{communicator}.
%We use communicators as message buffers between two arbitrary processes: a
%\emph{sender} and a \emph{receiver}.
%The communicator is connected to both the sender and the receiver using a shared
%channel.
%
%Intuitively, the communicator receives \emph{push} requests from the sender followed
%by receiving a message and stores them internally.
%Analogously, the communicator receives \emph{pop} requests from the receiver,
%and responds appropriately with the message if one is stored inside the communicator.
%Formally, a communicator has the following polymorphic session type
%\begin{tabbing}
%  $\mi{stype} \; \m{comm[K][msg]\{n\}} =$\\
%  \quad $\up \tgetpot{}{n+1: K} \echoice{$\=$\mb{SEND} : \m{msg} \arrow
%  \down \m{comm[msg]},$\\
%  \>$\mb{RECV} : \ichoice{$\=$\mb{yes} : \m{msg} \product \down \tpaypot{}{n: K} \m{comm[msg]},$\\
%  \>\>$\mb{no} : \down \m{comm[msg]} }}$
%\end{tabbing}
%The $\up$ indicates that it is a shared channel that must be \emph{acquired} by a process in order to send something over it.
%
%The sender can $\mb{SEND}$ a message into the communicator, and the receiver can periodically try to $\mb{RECV}$ a message from it.
%If there is a message, it responds with $\mb{yes}$, the message of the parameterized type $\m{msg}$, and the import sent with it.
%Note that the communicator retains one unit of import from every message. 
%It needs at least one because it may be activated a polynomial number of times, and, therefore a constant amount of potential is insufficient. 
%At the end of activation, the channel is released with $\down$, and another process can acquire it.

\subsection{Discussion on Realizing Import}
Our adaptation of the import mechanism to resource-aware session types concretizes some parts of the import mechanism like the run-time budget and adds new mechanisms
to facilitate common UC design pattersn such as simulation and virtualization of machines. 
It's important to validate our realization of the import mechanism by ensuring that it faithfully provides the same guarantees.
Furthermore, in this section we discuss existing pitfalls and drawbacks of prior mechanisms that import was created to over come, and assert that our implementation steers clear of them as well.

An important part of our discussion must focus around our sandboxing technique and ensuring that it does not provide a pathway for a process to run infinitely.
The infinite runs problems is a persistent issue in existing length-of-input based approaches to polynoimal time.
It naturally appears in our sandboxing mechanism by the continual creation of new virtual token types. Following from the intent of sandboxing, the NomosUC rule for a valid token context ensures that all virtual token types  \todo{ finish this by deciding which rule to update: \inline{genPot} or \inline{withdrawTokens}}

%\begin{itemize}
%\item Identify design decisions like concretizing potential, sandboxing and virtualizing with withdrawTokens, the valid token context rule, the type system in general
%\item Identify polytime concerns that need to be discussed in the context of our polytime design
%	\begin{itemize}
%	\item is PPT efficiently recognizable?
%	\item address the infinite runs problem and make sure it isn't allowed here with particular attention paid to withdrawTokens and infinite virtualizations
%	\item the type system guarantees we don't have a case where, given some polynomial, a machine just halts mid execution so we avoid any additional information that an environment can use to distinguish based on execution timing in both word
%	\end{itemize}
%\item end with the virtualization point and tie that into proposition 7 and the universal turing machine that can simulate the UC execution. This goes a long way in assuring PPT notion in NomosUC, even thought we aren't dealing exactly with ITMs here.
%\end{itemize}

%The type $\m{comm}$ is parameterized by the type $\m{msg}$, i.e., the type of
%messages in the buffer, and import type parameter, i.e. the amount of import tokens sent with
%the message. 
%The type initiates with an $\up$ denoting that $\m{comm}$ is a shared session type.
%The type prescribes that the communicator needs to be acquired by the sender (or receiver)
%for further interaction.
%Such an acquire-release discipline is automatically enforced by the shared session type.
%Once acquired, the communicator can either receive $\mb{push}$ (from sender) or
%$\mb{pop}$ requests (from receiver).
%In the former case, the communicator receives a message of type $\m{msg}$ and $n+1:K$ import tokens, and
%then detaches from the client using the dual $\down$ operator.
%In the latter case, the communicator checks if it internally contains a message
%for the receiver.
%If yes, the communicator replies with the $\mb{yesmsg}$ label followed by sending
%the message (the $\product$ constructor) and $n:K$ import tokens.
%Otherwise, the communicator replies with the $\mb{nomsg}$ label.
%In either case, the communicator then detaches from the client matching the $\down$
%operator.
%Internally, the communicator stores these messages in a first-in-first-out order.

%It is important to note that our communicators need at least 1 token of import 
%to use themselves to handle a potentially polynomial number of activations. 
%Therefore, it requires $n+1$ units of import from the sender and sends the intended
%$n$ tokens to the receiver when requested.

%The communicator is also the perfect opportunity to implement an unreliable
%message buffer that can drop or reorder messages.
%All we would need to do is change the internal implementation of the communicator
%\emph{without} changing the offered session type.
