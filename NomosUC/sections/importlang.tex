A major contribution of NomosUC is its ability to ensure resource-bounded computation
as dictated by UC guidelines.
To this end, we introduce a static notion of \emph{import tokens} that provide a static upper
bound on the execution cost of NomosUC programs.

\paragraph*{\textbf{Import Tokens}}
The core aspect of NomosUC is the integration of import tokens with the type system
enabling a static reasoning of the import mechanism in NomosUC.
To this end, we introduce a novel token context $\Tokens$ in the typing judgment to
represent the real and virtual tokens that a process possesses.

Before we explain the token context further, we motivate the need for virtual tokens.
A common scenario in UC is to simulate the execution of other ITMs within a \emph{sandbox},
where one ITM executes the code of another ITM in a controlled and enclosed environment.
We wish to support the same sandboxed execution in NomosUC.
However, to ensure bounded computation, we need to bound the computational cost of a
sandboxed execution as well.
And the only mechanism to bound the cost of an exection is via import tokens.
However, virtual execution within a sandbox must not cost real import tokens.
For instance, consider a process $P$ storing $t$ real import tokens that wishes to
simulate the execution of $Q$ within a sandbox in a way that $Q$ requires $t$
import tokens.
If $P$ transfers all its import to $Q$, $P$ will not be able to perform any execution of its own.

To address this issue, we introduce the concept of \emph{virtual tokens} that can be
created using the real import tokens that a process contains.
In the aforementioned situation, $P$ will create $t$ virtual tokens from its real import
which can then be used to simluate the execution of $Q$, while the $t$ real tokens are retained within $P$
allowing it to have its own execution.
In effect, the sandboxed execution is internal to a process and therefore must obey the resource (import token)
constraints provided to it.~\footnote{As far as resource-contraints go, simulating a process should be no different
from natively executing its code.}

Formally, every process contains a unique real token type, which we call type $K_0$, by default.
There is no mechanism to create a real token; when a process is spawned (whether in a sandbox or not),
the parent process must specify the real token type and quantity for the newly spawned process.
Virtual tokens, on the other hand, can be created (under certain conditions, see below) by a process.
To ensure bounded execution, we require all tokens follow a \emph{token hierarchy}: $K_0 \to K_1 \to K_2 \to \ldots K_m$
such that we can only use tokens of type $K_i$ to construct tokens of type $K_{i+1}$.
However, allowing processes to create an unbounded number of virtual token types would lead to
an unbounded computational cost.
Thus, we statically fix all the virtual token types along with their hierarchy in a NomosUC program.
For instance, to define the above hierarchy, the programmer writes
\begin{lstlisting}[basicstyle=\footnotesize\BeraMonottFamily]
  token types K0 -> K1 -> ... -> Km
\end{lstlisting}
and then the programmer can only use one of these $m$ token types in their process definitions.
We call $m$ the \emph{simulation depth} of the program, allowing sandboxed processes to execute their
own sandboxes upto a depth of $m$.

The token context of a process, written as $\Tokens$ in its typing judgment, maintains the number
of tokens of each type stored in it.
We use the notation $K \hookrightarrow (t, t')$ to express the total and current number of tokens
of type $K$ stored in the process.
The total number here represents the amount of tokens created of that type, so whenever we create
new tokens of type $K$, we increment the total.
The current number, on the other hand, tracks the amount of tokens currently owned by the process,
so whenever tokens are exchanged, they only impact the current token quantity and not the total.
The distinction helps us ensure bounded execution as exemplified by the validity of a token context, explained below.

For a process to be well-typed, an implicit side condition is
that its token context must always be \emph{valid w.r.t. the security parameter $k$}.
To this end, we introduce a fixed and globally known function $\GlobalF$ as the \emph{connection rate}
between two successive tokens in the hierarchy.
Then, we require that if $\Tokens$ contains $m'$ current tokens of type
$K_i$, it can only contain at most $\GlobalF(m,k)$ total tokens of type
$K_{i+1}$. We express this validity condition using the following inductive rules below.
\begin{mathpar}
  \infer
  {K_0 \hookrightarrow (t_0, t_0') \;\; \m{valid}(k)}
  {}
  \and
  \infer
  {\Tokens, K_{i+1} \hookrightarrow (t_{i+1}, t_{i+1}')\;\; \m{valid}(k)}
  {\Tokens\;\; \m{valid}(k) \and
  K_{i} \hookrightarrow (t_i, t_i') \in \Tokens \and
  t_{i+1} \leq \GlobalF(t_i',k)}
\end{mathpar}
Since validity of a token context is a side condition, we mandate
that it is implicitly satisfied by all the process typing rules
presented in our paper.
From the viewpoint of a NomosUC implementation, this validity check only
needs to be performed when the token context undergoes a change.

We now present the process typing rules that impact the token context $\Tokens$.
As a first step in introducing program notation for import tokens, we need 
syntax for creating new tokens of a given token type.
We call this construct $\m{withdrawToken} \; K_i \; n \; K_{i+1}$.
\begin{mathpar}
  \inferrule*[right=$\m{tok}$]
  {\Tokens, K_{i+1} \hookrightarrow (t_{i+1} + n, t_{i+1}' + n) \semi
  \Psi \semi\wt, \D \entailpot{\B{q}}{\B{q'}} P :: (x : A)}
  {\Tokens, K_{i+1} \hookrightarrow (t_{i+1}, t_{i+1}') \semi \Psi \semi \wt, \D \entailpot{\B{q}}{\B{q'}} \hspace{4em} \\
    \hspace{5em}\m{withdrawToken} \; K_i \; n\; K_{i+1}  \semi P :: (x : A)}
\end{mathpar}
The above construct generates $n$ new tokens of type $K_{i+1}$ and adds
them to both the total and current count for $K_{i+1}$ in the token
context $\Tokens$.
The implicit side condition of the validity of the token context ensures
that $t_{i+1} + n \leq \GlobalF(t_i',k)$ where $K_i \hookrightarrow (t_i, t_i') \in \Tokens$.
If this side condition fails, the above construct would fail to typecheck.

In addition, we also introduce two dual constructs for exchanging tokens
between processes.
To this end, we first introduce two new type constructors.
\begin{center}
\begin{minipage}{0cm}
\begin{tabbing}
$A ::= \ldots \mid \tpaypot{A}{r : K} \mid \tgetpot{A}{r : K}$
\end{tabbing}
\end{minipage}
\end{center}
The provider of $x : \tgetpot{A}{r : K}$ is required to receive
$r$ import tokens of type $K$ from the client using the construct
$\eget{x}{r : K}$. Dually, the client needs to pay this import
using the construct $\epay{x}{r : K}$.
The corresponding typing rules are
\begin{mathpar}
  \infer[\getpot R]
  {\Tokens, K_i \hookrightarrow (t_i, t_i') \semi \Psi \semi \D \entailpot{\B{q}}{\B{q'}} \eget{x}{r : K_i} \semi P ::
  (x : \tgetpot{A}{r : K_i})}
  {\Tokens, K_i \hookrightarrow (t_i, t_i'+r) \semi \Psi \semi \wt, \D \entailpot{\B{q}}{\B{q'}} P :: (x : A)}
  %
  \and
  %
  \infer[\getpot L]
  {\Tokens, K_i \hookrightarrow (t_i, t_i'+r) \semi \Psi \semi \wt, \D, (x : \tgetpot{A}{r : K_i}) \entailpot{\B{q}}{\B{q'}}
  \epay{x}{r : K_i} \semi P :: (z : C)}
  {\Tokens, K_i \hookrightarrow (t_i, t_i') \semi \Psi \semi \D, (x : A) \entailpot{\B{q}}{\B{q'}} P :: (z : C)}
\end{mathpar}
In the rule $\getpot R$, process $P$ storing $(t_i, t_i')$ import tokens of type $K_i$
receives $r$ additional $K_i$ tokens adding it to the current token counter, thus
the continuation executes with $(t_i, t_i'+r)$ tokens of type $K_i$.
Note that validity of token context is trivially satisfied in this case since the
process is gaining import tokens.
%
In the dual rule $\getpot L$, a process containing $(t_i, t_i'+r)$ tokens of type $K_i$
pays $r$ units along channel $x$ leaving $(t_i, t_i')$ import tokens of type $K_i$ with
the continuation.
In this case, the validity of the token context establishes that $t_{i+1} \leq \GlobalF(t_i',k)$,
a condition that is necessary for successful typechecking.
The typing rules for the dual constructor $\tpaypot{A}{r : K}$
are the exact inverse and omitted for brevity.
Similar to prior rules, the sender of the import tokens transfers the write token $\wt$
along with the import to the receiver.

The need for virtual tokens in UC arises because machines often simulate
other machines as part of their construction. The program notation for \msf{withdrawToken}
does not require an inverse to exchange tokens \textit{back} from type $K'$ to $K$.
The reason is that virtual tokens only exist to allow re-use of existing processes 
and satisfy their types. Type $K$ tokens are not deducted when new ones of type $K'$ 
are created is because, in reality, simulating a process by calling it or simply running
its code natively should be equivalent in cost. Therefore, there is also no need to 
include an inverse of \msf{withdrawToken} which exchanges from $K'$ to $K$.

\paragraph*{\textbf{Process Definitions and Sandboxing}}
Process definitions in NomosUC have the form
$\Psi \semi \D \vdash f\{t : K\} :: (x : A) = P$ where $f$
is the name of the process and $P$ its definition.
In addition, $\Psi$ and $\D$ denote the functional variables and session-typed channels
used by $f$ respectively while offering type $A$ on channel $x$.
In addition, $K$ is the real token type for $f$ and we need $t$ tokens of type $K$
to spawn $f$.
All definitions are collected in a fixed global process signature $\Sg$.
Also, since process definitions are mutually recursive, it is required that
for every process in the signature is well-typed w.r.t. $\Sg$.
This, in effect, requires us checking that each process definition obeys the type
specified for it in its signature.
Formally, for every definition of the form $\Psi \semi \D \vdash f\{t : K\} :: (x : A) = P$ in $\Sg$,
we are required to check $K \hookrightarrow (t, t) \semi \Psi \semi \D \entailpot{0}{0} P :: (x : A)$
\footnote{A process always starts with no potential, the reasoning for which is explained later}.
Note that every process initiates with only one token type, i.e., its real token type,
and hence, its token context is trivially valid. 

But how is a new process spawned and how is the real token type for a newly spawned
process determined?
A new instance of a defined process $f$ can be spawned with
the expression $\procdef{f\{r : K\}}{\overline{y}}{x} \semi Q$
where $\overline{y}$ is a sequence of variables matching the
antecedents $\Psi$ and $\D$, and the real token type for $f$ is $K$ with quantity $r$.
Sometimes a process invocation is a \emph{tail call}, written without
a continuation as $\procdef{f\{r : K\}}{\overline{y}}{x}$.
This is a short-hand for
$\procdef{f\{r : K\}}{\overline{y}}{x'} \semi \fwd{x}{x'}$ for a
fresh variable $x'$, that is, a fresh channel is created and
immediately identified with $x$.
A process spawn is typed as follows.
\begin{mathpar}
\inferrule*[right = $\m{spawn}$]
  {\Psi_1 \semi \D_1 \vdash f\{r : K\} :: (x : A) = P \in \Sg \and
  (\Psi_1 \semi \D_1) = \overline{y} \and
  \B{\Psi \share (\Psi_1, \Psi_2)} \\
  \Tokens, K \hookrightarrow (t, t') \semi \Psi_2 \semi \D_2, (x : A) \entailpot{\B{q}}{\B{q'}} Q :: (z : C)}
  {\Tokens, K \hookrightarrow (t, t'+r) \semi \Psi \semi \D_1, \D_2 \entailpot{\B{q}}{\B{q'}} \procdef{f\{r : K\}}{\overline{y}}{x} \semi Q ::
  (z : C)}
\end{mathpar}
We first look up the definition of $f$ in the signature $\Sg$
and match the arguments $\Psi$ and $\D$ with $\overline{y}$.
Next, we deduct $r$ token units of type $K$ from the current value of $K$
in the token context.
Finally, spawning the new process also creates channel $x : A$
which appears in the context for the typing of the continuation $Q$.

Remarkably, we can use the same syntactic construct for spawning
processes, whether it is a regular or sandboxed spawn.
Semantically, they are distinguished based on the token parameter.
For a regular spawn, the parent process passes in the real token type $K_0$,
while for a sandboxed call, a virtual token type $K_i (i > 0)$ is passed in.
We have a similar distinction for $\m{pay}$ and $\m{get}$ expressions:
if a real token is passed into these terms, it's a regular token
exchange; if a virtual token is passed in, it's a sandboxed $\m{pay}$
and $\m{get}$.

\paragraph*{\textbf{Potential}}
The main purpose of introducing import tokens was to bound the execution cost of ITMs.
But how do we connect import to the execution cost?
To this end, we introduce the notion of \emph{potential} in NomosUC to establish this connection.
Potential is an abstract quantity represented by a natural number stored
within each process.
To take an execution step, a process consumes \emph{one} unit of potential.
Therefore, the total potential stored in a process provides an upper bound on the total
number of execution steps that will ever be taken by the process.
To obtain a static upper bound, we integrate potential into the process typing judgment.
The symbol $\entailpot{q}{q'}$ denotes that the process stores $q$ and $q'$ units of
total and current potential (similar to total and current import).

Finally, the source of potential is the import tokens, completing the connection between
import and execution cost.
To this end, we introduce a novel construct $\m{genPot} \; r$ to generate potential
based on how much import is stored in the process.
\begin{mathpar}
  \inferrule*[right=$\m{pot}$]
  {q+r \leq \GlobalF(t_{m}',k) \and K_{m} \hookrightarrow (t_{m}, t_{m}') \in \Tokens \and
  k \semi \Tokens \semi \Psi \semi \wt, \D \entailpot{q+r}{q'+r} P :: (x : A)}
  {k \semi \Tokens \semi \Psi \semi \wt, \D \entailpot{q}{q'} \m{genPot} \; r \semi P :: (x : A)}
\end{mathpar}
A process initially storing $(q, q')$ potential units generates $r$ potential so that
the continuation contains $(q+r, q'+r)$ potential units.
Note, however, that the maximum potential that can be stored in a process is bounded by $\GlobalF(t_{m}',k)$
where $\GlobalF$ is the connection rate, $m$ is the simulation depth, and $k$ is the security parameter.
This restricts us from generating an unbounded amount of potential which could have violated the
polynomial execution cost bound.

The purpose of introducing potential into NomosUC is to bound the
number of execution steps.
To this end, we assign a cost of 1 per syntactic construct introduced so far.
But this would cause potential to creep in all our typing rules, essentially deducting $1$ potential unit
from the process in each rule.
Instead, we simplify matters by introducing a $\etick{r}$ construct that consumes $r$
potential from the current stored process potential, as described below.
\begin{mathpar}
  \infer[\m{tick}]
  {\Tokens \semi \Psi \semi \wt, \D \entailpot{q}{q'+r} \etick{r} \semi P :: (x : A)}
  {\Tokens \semi \Psi \semi \wt, \D \entailpot{q}{q'} P :: (x : A)}
\end{mathpar}
Note how the process starts with $q'+r$ potential units, and executing $\etick{r}$
consumes $r$ units leaving $q'$ potential for the continuation.

The implementation of NomosUC can integrate a cost instrumentation engine that automatically
inserts a $\etick{1}$ construct before each syntactic construct.
This enables us to simulate the cost model that counts the total number of
execution steps.

% \begin{mathpar}
%   \D_1 \equiv_Z \D_2 \\
%   \D \overset{(import, potential, cost)}{\vDash} P :: \D' \\
%   A \equiv B \\
%   \infer[]
%   {\vars \vdash \D_1, (x : A) \equiv \D_2, (x : B)}
%   {\vars \vdash \D_1 \equiv \D_2 \and \vars \vdash A \equiv B}
% \end{mathpar}





\subsection{Preservation and Progress}
The main type safety theorems that exhibit the deep connection between our type
system and the operational semantics are the usual \emph{type
preservation} and \emph{progress}, sometimes called \emph{session
fidelity} and \emph{deadlock freedom}, respectively.

To exhibit these theorems, we first need to introduce semantic objects
$\proc{c}{w, P}$ and $\msg{c}{w, M}$.
The former (resp. latter) denotes a process (resp. message) executing
expression $P$ (resp. $M$) offering channel $c$ and having performed
work $w$ so far.
The work counter keeps track of execution steps taken by a process,
giving rise to the following semantics rule:
\begin{tabbing}
  $(\m{tick}) : \proc{c}{w, \etick{r} \semi P} \step \proc{c}{w+r, P}$
\end{tabbing}
A multiset of such semantic objects communicating with each other
is known as a \emph{configuration}.
A configuration is typed w.r.t. a signature providing the type declaration
of each process.
A signature $\Sg$ is \emph{well formed} if
(a) every type definition $V = A_V$ is \emph{contractive},
and (b) every process definition
$\Psi \semi \D \vdash f \{\Tokens\} = P :: (x : A)$ in $\Sg$
is well typed according to the process typing judgment, i.e.
$\Tokens \semi \Psi \semi \D \vdash P :: (x : A)$.
 
A key question then is how to type these configurations.
Since they consist of both processes and messages, they
both \emph{use} and \emph{provide} a collection of channels.
Another goal with the type safety theorems is to establish a connection
between the statically determined import tokens of a process,
its total potential, and the dynamically evolving work counters
that account for the total number of execution steps.
We use the following judgment to type a configuration.
\[
\D_1 \overset{(T, Q)}{\underset{W}{\vDash}} \config :: \D_2
\]
It states that the configuration $\config$
uses the channels in the context $\D_1$ and provides the channels in
the context $\D_2$.
In addition, $T$ and $Q$denote the total number of real tokens
potential contained in a configuration.
Similarly, $W$ denotes the total work performed by a configuration.
All these quantities are computed by adding the individual tokens,
potential, and work of each semantic object.
\begin{figure}[t]
\begin{mathpar}
\infer[\m{empty}]
{\D \overset{(0, 0)}{\underset{0}{\vDash}} (\cdot) :: \D}
{}
\and
\infer[\m{compose}]
{\D_0 \overset{(T_1+T_2, Q_1+Q_2)}{\underset{W_1+W_2}{\vDash}} (\config_1 \; \config_2) :: \D_2}
{\D_0 \overset{(T_1, Q_1)}{\underset{W_1}{\vDash}} \config_1 :: \D_1 \qquad
\D_1 \overset{(T_2, Q_2)}{\underset{W_2}{\vDash}} \config_2 :: \D_2}
\and
\infer[\m{proc}]
{\D, \D_1 \overset{(t, q)}{\underset{w}{\vDash}} \proc{c}{w, P} :: (\D, (c : A) )}
{\Tokens, K_0 \hookrightarrow t \semi \cdot \semi \D_1 \entailpot{q} P :: (c : A)}
\and
\infer[\m{msg}]
{\D, \D_1 \overset{(t, q)}{\underset{w}{\vDash}} \msg{c}{w, M} :: (\D, (c : A) )}
{\Tokens, K_0 \hookrightarrow t \semi \cdot \semi \D_1 \entailpot{q} M :: (c : A)}
\end{mathpar}
\caption{Typing rules for a configuration}
\label{fig:config_typing}
\end{figure}

The configuration typing judgment is defined using
the rules presented in Figure~\ref{fig:config_typing}.
%
The rule $\m{empty}$ defines that an empty configuration
is well-typed with $(T, Q, W) = (0, 0, 0)$ and uses and
provides the same set of channels.
The $\m{compose}$ rule combines two configurations by canceling out
the common channels and adding the individual tokens, potential, and work.
The $\m{proc}$ rule creates a configuration out of a single process
and uses its tokens, potential, and work as the annotations for the
configuration.
Similarly, the $\m{msg}$ rule creates a configuration out of a single message.

\begin{theorem}[Type Preservation]
\label{thm:preservation}
Suppose we have a well-typed configuration
$\D \overset{(T_1, Q_1)}{\underset{W_1}{\vDash}} \config_1 :: \D'$ such
that there exists a polynomial $\mathfrak{p}$ such that $\mathfrak{p}(T_1) \geq Q_1+W_1$.
If $\config_1 \step \config_2$, then there exist $T_2$, $Q_2$, and $W_2$ such
that $\D \overset{(T_2, Q_2)}{\underset{W_2}{\vDash}} \config_2 :: \D'$,
and $\mathfrak{p}(T_2) \geq Q_2+W_2$.
\end{theorem}
\begin{proof}
  By case analysis on the transition rule, applying inversion to the
  given typing derivation, and then assembling a new derivation of
  $\dc$.
\end{proof}

A process or message is said to be \emph{poised} if it is trying to
communicate along the channel that it provides.  A poised process is
comparable to a value in a sequential language. A configuration is
poised if every process or message in the configuration is poised.
Conceptually, this implies that the configuration is trying to communicate
externally, i.e. along one of the channel it provides.
The progress theorem then shows that either a configuration can take a
step or it is poised.  To prove this I show first that the typing
derivation can be rearranged to go strictly from right to left and
then proceed by induction over this particular derivation.

\begin{theorem}[Global Progress]
\label{thm:progress}
\mbox{}
If $\cdot \overset{(T, Q)}{\underset{W}{\vDash}} \config :: \D$ then either
\begin{enumerate}
\item[(i)] $\config \mapsto \config'$ for some $\config'$, or
\item[(ii)] $\config$ is poised.
\end{enumerate}
\end{theorem}
\begin{proof}
By induction on the right-to-left typing of $\config$ so that either
$\config$ is empty (and therefore poised) or
$\config = (\dc\; \proc{c}{w, P})$ or
$\config = (\dc\; \msg{c}{w, M})$. By induction hypothesis, $\dc$ can
either take a step (and then so can $\config$), or $\dc$ is poised.  In
the latter case, I
analyze the cases for $P$ and $M$, applying multiple steps of
inversion to show that in each
case either $\config$ can take a step or is poised.
\end{proof}


%\subsection{UC Communicators} \label{sec:communicators}
%% all the processes conncted together leads to a cycle of linear channels ==> Z <--> P so here we use a communicator 
%The UC execution connects the protocol to the environment in both directions of communication.
%This poses a technical challenge where, if linear channels are used, the resulting topology contains a cycle of linear channels: the environmtne offers a channel to the wrapper and the wrapper to the environment.
%Such cycles violate type preservation because a client is acquiring its client~\ref{dasnomos}.
%Therefore, we use a message buffers called communicators which offered shared channels that both ends of the communication can use.
%Communicators are used in the main UC execution in Section~\ref{sec:execuc} to connect the main processes together, as well as within the \partywrapper. 
%
%A communicator has a \emph{sender} and a \emph{receiver}. 
%The shared channel offered by the communicator has the following polymorphic session type:
%\begin{tabbing}
%  $\mi{stype} \; \m{comm[K][msg]\{n\}} =$\\
%  \quad $\up \tgetpot{}{n+1: K} \echoice{$\=$\mb{push} : \m{msg} \arrow
%  \down \m{comm[msg]},$\\
%  \>$\mb{pop} : \ichoice{$\=$\mb{yesmsg} : \m{msg} \product \down \tpaypot{}{n: K} \m{comm[msg]},$\\
%  \>\>$\mb{nomsg} : \down \m{comm[msg]} }}$
%\end{tabbing}
%
%One illustration of the use of shared session types is a \emph{communicator}.
%We use communicators as message buffers between two arbitrary processes: a
%\emph{sender} and a \emph{receiver}.
%The communicator is connected to both the sender and the receiver using a shared
%channel.
%
%Intuitively, the communicator receives \emph{push} requests from the sender followed
%by receiving a message and stores them internally.
%Analogously, the communicator receives \emph{pop} requests from the receiver,
%and responds appropriately with the message if one is stored inside the communicator.
%Formally, a communicator has the following polymorphic session type
%\begin{tabbing}
%  $\mi{stype} \; \m{comm[K][msg]\{n\}} =$\\
%  \quad $\up \tgetpot{}{n+1: K} \echoice{$\=$\mb{SEND} : \m{msg} \arrow
%  \down \m{comm[msg]},$\\
%  \>$\mb{RECV} : \ichoice{$\=$\mb{yes} : \m{msg} \product \down \tpaypot{}{n: K} \m{comm[msg]},$\\
%  \>\>$\mb{no} : \down \m{comm[msg]} }}$
%\end{tabbing}
%The $\up$ indicates that it is a shared channel that must be \emph{acquired} by a process in order to send something over it.
%
%The sender can $\mb{SEND}$ a message into the communicator, and the receiver can periodically try to $\mb{RECV}$ a message from it.
%If there is a message, it responds with $\mb{yes}$, the message of the parameterized type $\m{msg}$, and the import sent with it.
%Note that the communicator retains one unit of import from every message. 
%It needs at least one because it may be activated a polynomial number of times, and, therefore a constant amount of potential is insufficient. 
%At the end of activation, the channel is released with $\down$, and another process can acquire it.

%%\subsection{Discussion on Realizing Import}
%%In this section we present a generic way of using communicators and shared channel to realize arbitrary communication between two parties, avoid cycles, and, still, meaningfully use session types.
%%A consequence of the approach is that communicators carry only functionally typed messages and, therefore, shell code needs to convert between them and session-typed messages.
%%Now that we have introduced the import and potential mechanisms in NomosUC, we introduce a final consequence of our design.
%%
%%The communicator type, and the functional messages, restrict all messages in one direction between two parties to send a constant amount of import.
%%This means that if a protocol requires sending different import with different messages, NomosUC realizes it be sending the maximal import with every message.
%%As the intent of import is not to impose very right bounds on resource usage, we argue that this constraint only results in users defining types that give more import than absolutely necessary.


%\begin{itemize}
%\item Identify design decisions like concretizing potential, sandboxing and virtualizing with withdrawTokens, the valid token context rule, the type system in general
%\item Identify polytime concerns that need to be discussed in the context of our polytime design
%	\begin{itemize}
%	\item is PPT efficiently recognizable?
%	\item address the infinite runs problem and make sure it isn't allowed here with particular attention paid to withdrawTokens and infinite virtualizations
%	\item the type system guarantees we don't have a case where, given some polynomial, a machine just halts mid execution so we avoid any additional information that an environment can use to distinguish based on execution timing in both word
%	\end{itemize}
%\item end with the virtualization point and tie that into proposition 7 and the universal turing machine that can simulate the UC execution. This goes a long way in assuring PPT notion in NomosUC, even thought we aren't dealing exactly with ITMs here.
%\end{itemize}

%The type $\m{comm}$ is parameterized by the type $\m{msg}$, i.e., the type of
%messages in the buffer, and import type parameter, i.e. the amount of import tokens sent with
%the message. 
%The type initiates with an $\up$ denoting that $\m{comm}$ is a shared session type.
%The type prescribes that the communicator needs to be acquired by the sender (or receiver)
%for further interaction.
%Such an acquire-release discipline is automatically enforced by the shared session type.
%Once acquired, the communicator can either receive $\mb{push}$ (from sender) or
%$\mb{pop}$ requests (from receiver).
%In the former case, the communicator receives a message of type $\m{msg}$ and $n+1:K$ import tokens, and
%then detaches from the client using the dual $\down$ operator.
%In the latter case, the communicator checks if it internally contains a message
%for the receiver.
%If yes, the communicator replies with the $\mb{yesmsg}$ label followed by sending
%the message (the $\product$ constructor) and $n:K$ import tokens.
%Otherwise, the communicator replies with the $\mb{nomsg}$ label.
%In either case, the communicator then detaches from the client matching the $\down$
%operator.
%Internally, the communicator stores these messages in a first-in-first-out order.

%It is important to note that our communicators need at least 1 token of import 
%to use themselves to handle a potentially polynomial number of activations. 
%Therefore, it requires $n+1$ units of import from the sender and sends the intended
%$n$ tokens to the receiver when requested.

%The communicator is also the perfect opportunity to implement an unreliable
%message buffer that can drop or reorder messages.
%All we would need to do is change the internal implementation of the communicator
%\emph{without} changing the offered session type.
